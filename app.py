from flask import Flask, request, jsonify, render_template, send_from_directory, session, redirect
from flask_cors import CORS
import pandas as pd
import os
from datetime import datetime
import requests
import re
# ================================================================
# ğŸ§± Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø°ÙƒÙŠØ© SEVENS (Ù…Ø²Ø§Ù…Ù†Ø© Ø«Ù†Ø§Ø¦ÙŠØ© Excel â†” SQLite)
# ================================================================
import sqlite3
import pandas as pd
import os
import time
import threading

import os
import ssl
import smtplib
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart
from dotenv import load_dotenv
import os
import ssl
import smtplib
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart
from dotenv import load_dotenv

load_dotenv()

SMTP_SERVER = os.getenv("SMTP_SERVER", "mail.sevens.sa")
SMTP_USER = os.getenv("SMTP_USER", "ticket.support@sevens.sa")
SMTP_PASSWORD = os.getenv("SMTP_PASSWORD")
SMTP_PORT = int(os.getenv("SMTP_PORT", "587"))

def send_html_email_via_company(to_email: str, subject: str, html_body: str):
    if not SMTP_PASSWORD:
        raise Exception("SMTP_PASSWORD is not set in .env")

    msg = MIMEMultipart("alternative")
    msg["To"] = to_email
    msg["From"] = f"SEVENS System <{SMTP_USER}>"
    msg["Subject"] = subject
    msg.attach(MIMEText(html_body, "html", "utf-8"))

    try:
        print(f"[SMTP] Connecting to {SMTP_SERVER}:{SMTP_PORT} as {SMTP_USER}")
        with smtplib.SMTP(SMTP_SERVER, SMTP_PORT, timeout=20) as server:
            server.ehlo()
            context = ssl.create_default_context()
            server.starttls(context=context)
            server.ehlo()
            server.login(SMTP_USER, SMTP_PASSWORD)
            server.sendmail(SMTP_USER, [to_email], msg.as_string())
        print(f"[SMTP] âœ… Email sent to {to_email}")
        return True

    except Exception as e:
        print("[SMTP] âŒ Failed to send email")
        import traceback
        traceback.print_exc()
        raise


BASE_DIR = os.path.dirname(os.path.abspath(__file__))
DB_SQLITE = os.path.join(BASE_DIR, "data", "sevens.db")
DATA_DIR = os.path.join(BASE_DIR, "data")
USERS_XLSX = os.path.join(DATA_DIR, "database.xlsx")
REQUESTS_XLSX = os.path.join(DATA_DIR, "requests.xlsx")
CHATS_XLSX = os.path.join(DATA_DIR, "chat_messages.xlsx")
# âœ… ØªØ¹Ø±ÙŠÙ Ø§Ù„Ù…Ø³Ø§Ø±Ø§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© ÙÙŠ Ø£Ø¹Ù„Ù‰ Ø§Ù„Ù…Ù„Ù
DATA_DIR = os.path.join(BASE_DIR, "data")
os.makedirs(DATA_DIR, exist_ok=True)

DB_PATH = os.path.join(DATA_DIR, "database.xlsx")         # Ù…Ù„Ù Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ†
REQUESTS_PATH = os.path.join(DATA_DIR, "requests.xlsx")   # Ù…Ù„Ù Ø§Ù„Ø·Ù„Ø¨Ø§Øª
CHAT_PATH = os.path.join(DATA_DIR, "chat_messages.xlsx")  # Ù…Ù„Ù Ø¯Ø±Ø¯Ø´Ø§Øª Ø§Ù„Ø·Ù„Ø¨Ø§Øª
REQUESTS_SHEET = "Ø§Ù„Ø·Ù„Ø¨Ø§Øª Ø¬Ù…ÙŠØ¹"


# ==== Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© ====
def init_sqlite():
    conn = sqlite3.connect(DB_SQLITE)
    c = conn.cursor()

    c.execute("""
    CREATE TABLE IF NOT EXISTS users (
        id INTEGER PRIMARY KEY AUTOINCREMENT,
        name TEXT,
        role TEXT,
        password TEXT,
        email TEXT UNIQUE,
        department TEXT,
        status TEXT DEFAULT 'Ù†Ø´Ø·',
        created_at TEXT DEFAULT CURRENT_TIMESTAMP
    )
    """)

    c.execute("""
    CREATE TABLE IF NOT EXISTS requests (
        id INTEGER PRIMARY KEY AUTOINCREMENT,
        req_id TEXT UNIQUE,
        date TEXT,
        title TEXT,
        description TEXT,
        sender_dept TEXT,
        receiver_dept TEXT,
        status TEXT,
        assigned_to TEXT,
        updated_by TEXT,
        duration TEXT,
        file_name TEXT,
        created_at TEXT DEFAULT CURRENT_TIMESTAMP
    )
    """)

    c.execute("""
    CREATE TABLE IF NOT EXISTS chats (
        id INTEGER PRIMARY KEY AUTOINCREMENT,
        req_id TEXT,
        sender_name TEXT,
        department TEXT,
        message TEXT,
        file_name TEXT,
        timestamp TEXT DEFAULT CURRENT_TIMESTAMP
    )
    """)

    c.execute("""
    CREATE TABLE IF NOT EXISTS logs (
        id INTEGER PRIMARY KEY AUTOINCREMENT,
        event TEXT,
        user TEXT,
        department TEXT,
        details TEXT,
        created_at TEXT DEFAULT CURRENT_TIMESTAMP
    )
    """)

    conn.commit()
    conn.close()
    print("âœ… SQLite structure ready")


# ==== ØªØ´ØºÙŠÙ„ Ø£ÙˆÙ„ÙŠ ====
if not os.path.exists(DB_SQLITE):
    print("ğŸ†• Creating SEVENS database...")
    init_sqlite()

else:
    print("â„¹ï¸ SEVENS database found â€” syncing now...")


# ğŸ”¹ Ø§Ù„Ù…Ø³Ø§Ø± Ø§Ù„Ø­Ø§Ù„ÙŠ (Ø¬Ø°Ø± Ø§Ù„Ù…Ø´Ø±ÙˆØ¹)
BASE_DIR = os.path.dirname(os.path.abspath(__file__))

# ğŸ”¹ ØªØ¹Ø±ÙŠÙ Flask Ù…Ø¹ Ø§Ù„Ù…Ø³Ø§Ø± Ø§Ù„ØµØ­ÙŠØ­ Ù„Ù„Ù‚ÙˆØ§Ù„Ø¨
app = Flask(
    __name__,
    template_folder="templates",
    static_folder="static"
)
app.secret_key = "SEVENS-SECRET-2025"
CORS(app, resources={r"/api/*": {"origins": "*"}})


# âœ… ØªØ¹Ø±ÙŠÙ Ø§Ù„Ù…Ø¬Ù„Ø¯ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ Ù„Ù„Ù…Ø´Ø±ÙˆØ¹
BASE_DIR = os.path.dirname(os.path.abspath(__file__))

# ========== ğŸ§© Google Drive Backup Integration ==========
from googleapiclient.discovery import build
from google.oauth2 import service_account
from googleapiclient.http import MediaFileUpload, MediaIoBaseDownload
import json

CONFIG_PATH = os.path.join(BASE_DIR, "config.json")

def load_config():
    """ØªØ­Ù…ÙŠÙ„ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ù†Ø³Ø® Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠ"""
    if not os.path.exists(CONFIG_PATH):
        default_conf = {
            "backup_mode": "local",  # Ø£Ùˆ "drive"
            "google_drive_folder_id": "",
            "service_key_path": os.path.join("data", "sevens-service-key.json")
        }
        with open(CONFIG_PATH, "w", encoding="utf-8") as f:
            json.dump(default_conf, f, ensure_ascii=False, indent=2)
        return default_conf
    with open(CONFIG_PATH, "r", encoding="utf-8") as f:
        return json.load(f)

CONFIG = load_config()
# âœ… ÙØ­Øµ Ø§ØªØµØ§Ù„ Google Drive Ø¹Ù†Ø¯ Ø§Ù„ØªØ´ØºÙŠÙ„
try:
    key_data = os.environ.get("GOOGLE_SERVICE_KEY", "").strip()
    if key_data:
        creds = service_account.Credentials.from_service_account_info(
            json.loads(key_data),
            scopes=["https://www.googleapis.com/auth/drive"]
        )

        service = build("drive", "v3", credentials=creds)
        about = service.about().get(fields="user").execute()
        user_email = about["user"]["emailAddress"]
        print(f"âœ… Google Drive connected successfully as: {user_email}")
    else:
        print("âš ï¸ GOOGLE_SERVICE_KEY not found (Drive backup disabled).")
except Exception as e:
    print("âŒ Google Drive connection test failed:", e)

def upload_to_drive(file_path):
    """Ø±ÙØ¹ Ù…Ù„Ù Ø¥Ù„Ù‰ Google Drive (Ù…Ø¹ Ù†Ù‚Ù„ Ø§Ù„Ù…Ù„ÙƒÙŠØ© Ø¥Ù„Ù‰ ØµØ§Ø­Ø¨ Ø§Ù„Ø­Ø³Ø§Ø¨ Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠ)"""
    try:
        if CONFIG.get("backup_mode") != "drive":
            print("ğŸŸ¡ Ø§Ù„Ù†Ø³Ø® Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠ Ø§Ù„Ù…Ø­Ù„ÙŠ Ù…ÙØ¹Ù„ (Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø±ÙØ¹ Ø¥Ù„Ù‰ Drive).")
            return

        key_data = os.environ.get("GOOGLE_SERVICE_KEY", "").strip()
        if not key_data:
            print("âš ï¸ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ GOOGLE_SERVICE_KEY ÙÙŠ Ø§Ù„Ø¨ÙŠØ¦Ø©.")
            return

        service_key = json.loads(key_data)
        creds = service_account.Credentials.from_service_account_info(
            service_key,
            scopes=["https://www.googleapis.com/auth/drive"]
        )
        service = build("drive", "v3", credentials=creds)

        folder_id = CONFIG.get("google_drive_folder_id")
        file_name = os.path.basename(file_path)
        file_metadata = {"name": file_name, "parents": [folder_id]}
        media = MediaFileUpload(file_path, resumable=True)

        # Ø±ÙØ¹ Ø§Ù„Ù…Ù„Ù
        uploaded = service.files().create(
            body=file_metadata,
            media_body=media,
            fields="id"
        ).execute()

        file_id = uploaded.get("id")

        # Ù†Ù‚Ù„ Ø§Ù„Ù…Ù„ÙƒÙŠØ© Ø¥Ù„Ù‰ Ø­Ø³Ø§Ø¨Ùƒ Ø§Ù„Ø´Ø®ØµÙŠ
        service.permissions().create(
            fileId=file_id,
            body={
                "type": "user",
                "role": "owner",
                "emailAddress": "sevensitapp@gmail.com"
            },
            transferOwnership=True
        ).execute()

        print(f"âœ… Backup uploaded & transferred ownership: {file_name}")
    except Exception as e:
        print("âŒ upload_to_drive error:", e)

# âœ… Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø¬Ù„Ø¯ Ø§Ù„Ø±ÙØ¹
UPLOAD_DIR = os.path.join(BASE_DIR, "uploads")
os.makedirs(UPLOAD_DIR, exist_ok=True)

# âœ… Ù…Ø³Ø§Ø± Ù…Ù„Ù Ø¯Ø±Ø¯Ø´Ø© Ø§Ù„Ø·Ù„Ø¨Ø§Øª
CHAT_PATH = os.path.join(BASE_DIR, "chat_messages.xlsx")

UPLOAD_DIR = os.path.join(BASE_DIR, "uploads")
os.makedirs(UPLOAD_DIR, exist_ok=True)

# âœ… Ù…Ø³Ø§Ø± Ù…Ù„Ù Ø¯Ø±Ø¯Ø´Ø© Ø§Ù„Ø·Ù„Ø¨Ø§Øª
CHAT_PATH = os.path.join(BASE_DIR, "chat_messages.xlsx")

from googleapiclient.errors import HttpError

def download_from_drive(file_name, local_path):
    """ğŸ“¥ ØªÙ†Ø²ÙŠÙ„ Ù…Ù„Ù Ù…Ù† Google Drive Ø¥Ù„Ù‰ Ø§Ù„Ø³ÙŠØ±ÙØ±"""
    try:
        key_data = os.environ.get("GOOGLE_SERVICE_KEY", "").strip()
        if not key_data:
            print("âš ï¸ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ GOOGLE_SERVICE_KEY ÙÙŠ Ø§Ù„Ø¨ÙŠØ¦Ø©.")
            return False

        service_key = json.loads(key_data)
        creds = service_account.Credentials.from_service_account_info(
            service_key,
            scopes=["https://www.googleapis.com/auth/drive"]
        )
        service = build("drive", "v3", credentials=creds)

        folder_id = CONFIG.get("google_drive_folder_id")
        query = f"'{folder_id}' in parents and name='{file_name}' and trashed=false"

        results = service.files().list(q=query, fields="files(id, name, modifiedTime)").execute()
        files = results.get("files", [])
        if not files:
            print(f"âš ï¸ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø§Ù„Ù…Ù„Ù {file_name} ÙÙŠ Google Drive.")
            return False

        # ğŸ“„ ØªÙ†Ø²ÙŠÙ„ Ø£Ø­Ø¯Ø« Ù†Ø³Ø®Ø© (Ø§Ù„Ø£Ø­Ø¯Ø« Ù…Ù† Ø­ÙŠØ« ÙˆÙ‚Øª Ø§Ù„ØªØ¹Ø¯ÙŠÙ„)
        file_id = sorted(files, key=lambda x: x["modifiedTime"], reverse=True)[0]["id"]

        request = service.files().get_media(fileId=file_id)
        with open(local_path, "wb") as f:
            downloader = MediaIoBaseDownload(f, request)
            done = False
            while not done:
                status, done = downloader.next_chunk()
                if status:
                    print(f"â¬‡ï¸ ØªØ­Ù…ÙŠÙ„ {file_name}: {int(status.progress() * 100)}%")
        print(f"âœ… ØªÙ… ØªÙ†Ø²ÙŠÙ„ Ø§Ù„Ù…Ù„Ù: {file_name}")
        return True

    except HttpError as e:
        print(f"âŒ Google API error Ø£Ø«Ù†Ø§Ø¡ ØªÙ†Ø²ÙŠÙ„ {file_name}: {e}")
        return False
    except Exception as e:
        print(f"âŒ Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ ØªÙ†Ø²ÙŠÙ„ {file_name}: {e}")
        return False


def load_chats():
    """ØªØ­Ù…ÙŠÙ„ Ø³Ø¬Ù„ Ø¯Ø±Ø¯Ø´Ø§Øª Ø§Ù„Ø·Ù„Ø¨Ø§Øª Ù…Ù† Ù…Ù„Ù Excel Ø£Ùˆ Ø¥Ù†Ø´Ø§Ø¤Ù‡ Ø¥Ù† Ù„Ù… ÙŠÙˆØ¬Ø¯"""
    if not os.path.exists(CHAT_PATH):
        df = pd.DataFrame(columns=['Ø±Ù‚Ù… Ø§Ù„Ø·Ù„Ø¨', 'Ø§Ù„Ù…Ø±Ø³Ù„', 'Ø§Ù„Ù‚Ø³Ù…', 'Ø§Ù„Ø±Ø³Ø§Ù„Ø©', 'Ø§Ù„Ù…Ù„Ù', 'Ø§Ù„ÙˆÙ‚Øª'])
        df.to_excel(CHAT_PATH, index=False)
        print("âœ… Created chat_messages.xlsx")
        return df
    try:
        df = pd.read_excel(CHAT_PATH)
        # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© ÙˆØªÙˆØ­ÙŠØ¯ Ø§Ù„Ø£Ø³Ù…Ø§Ø¡
        df.columns = [str(c).strip() for c in df.columns]
        for col in ['Ø±Ù‚Ù… Ø§Ù„Ø·Ù„Ø¨', 'Ø§Ù„Ù…Ø±Ø³Ù„', 'Ø§Ù„Ù‚Ø³Ù…', 'Ø§Ù„Ø±Ø³Ø§Ù„Ø©', 'Ø§Ù„Ù…Ù„Ù', 'Ø§Ù„ÙˆÙ‚Øª']:
            if col not in df.columns:
                df[col] = ''
        return df
    except Exception as e:
        print("âŒ load_chats error:", e)
        return pd.DataFrame(columns=['Ø±Ù‚Ù… Ø§Ù„Ø·Ù„Ø¨', 'Ø§Ù„Ù…Ø±Ø³Ù„', 'Ø§Ù„Ù‚Ø³Ù…', 'Ø§Ù„Ø±Ø³Ø§Ù„Ø©', 'Ø§Ù„Ù…Ù„Ù', 'Ø§Ù„ÙˆÙ‚Øª'])

def normalize_arabic(text):
    if not isinstance(text, str):
        text = str(text)

    text = text.strip()

    # Ø¥Ø²Ø§Ù„Ø© Ù…Ø®ÙÙŠ
    text = text.replace('\u200f','').replace('\u200e','')

    # ØªÙˆØ­ÙŠØ¯ Ø£Ù„Ù ÙˆØ§Ù„Ù‡Ù…Ø²Ø§Øª
    text = re.sub(r'[Ø¥Ø£Ø¢Ø§]', 'Ø§', text)


    # ØªØ§Ø¡ Ù…Ø±Ø¨ÙˆØ·Ø©
    text = text.replace('Ø©','Ø©')

    # ÙƒÙ„Ù…Ø© Ø¥Ø¯Ø§Ø±Ø©
    text = text.replace('Ø§Ø¯Ø§Ø±Ù‡','Ø§Ø¯Ø§Ø±Ø©')
    text = text.replace('Ø§Ø¯Ø§Ø±Ø©','Ø§Ø¯Ø§Ø±Ø©')
    text = text.replace('Ø§Ø¯Ø±Ù‡','Ø§Ø¯Ø§Ø±Ø©')
    text = text.replace('Ø§Ù„Ø§Ø¯Ø§Ø±Ù‡','Ø§Ø¯Ø§Ø±Ø©')
    text = text.replace('Ø§Ù„Ø§Ø¯Ø§Ø±Ø©','Ø§Ø¯Ø§Ø±Ø©')

    return text

# ============== Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø¹Ø§Ù…Ø© ==============
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
REQUESTS_SHEET = "Ø§Ù„Ø·Ù„Ø¨Ø§Øª Ø¬Ù…ÙŠØ¹"
EXPORT_DIR = os.path.join(BASE_DIR, "exports")
os.makedirs(EXPORT_DIR, exist_ok=True)

## Ù…ÙØªØ§Ø­ ÙˆØ§Ø¬Ù‡Ø© OpenRouter API  (Ø§Ø­ØµÙ„ Ø¹Ù„ÙŠÙ‡ Ù…Ù† https://openrouter.ai)
OPENROUTER_API_KEY = "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"

# âœ… Ø§Ø³ØªØ±Ø¬Ø§Ø¹ Ø§Ù„Ù†Ø³Ø® Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠØ© Ù‚Ø¨Ù„ Ø§Ù„ØªØ´ØºÙŠÙ„ (ÙÙŠ Ø­Ø§Ù„ Ø§Ù„Ù…Ù„ÙØ§Øª Ù…ÙÙ‚ÙˆØ¯Ø©)
for fpath, fname in [
    (DB_PATH, "database.xlsx"),
    (REQUESTS_PATH, "requests.xlsx"),
    (CHAT_PATH, "chat_messages.xlsx"),
]:
    if not os.path.exists(fpath):
        print(f"ğŸ“¥ Ø§Ù„Ù…Ù„Ù {fname} Ù…ÙÙ‚ÙˆØ¯ØŒ Ø³ÙŠØªÙ… Ø§Ø³ØªØ±Ø¬Ø§Ø¹Ù‡ Ù…Ù† Google Drive...")
        download_from_drive(fname, fpath)

# ============== Ø¯ÙˆØ§Ù„ Ù…Ø³Ø§Ø¹Ø¯Ø© ==============
def ensure_excel_exists():
    if not os.path.exists(DB_PATH):
        users_cols = ['Ø§Ù„Ø§Ø³Ù…', 'Ø§Ù„ØµÙ„Ø§Ø­ÙŠØ©', 'ÙƒÙ„Ù…Ø© Ø§Ù„Ù…Ø±ÙˆØ±', 'Ø§Ù„Ø¨Ø±ÙŠØ¯ Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠ', 'Ø§Ù„Ù‚Ø³Ù…']
        pd.DataFrame(columns=users_cols).to_excel(DB_PATH, index=False)
        print("âœ… Created users DB")

    if not os.path.exists(REQUESTS_PATH):
        req_cols = ['Ø±Ù‚Ù… Ø§Ù„Ø·Ù„Ø¨', 'Ø§Ù„ØªØ§Ø±ÙŠØ®', 'Ø§Ù„Ø¹Ù†ÙˆØ§Ù†', 'Ø§Ù„ÙˆØµÙ', 'Ø§Ù„Ù‚Ø³Ù… Ø§Ù„Ù…Ø±Ø³Ù„',
                    'Ø§Ù„Ù‚Ø³Ù… Ø§Ù„Ù…Ø³ØªÙ„Ù…', 'Ø§Ù„Ø­Ø§Ù„Ø©', 'Ø§Ù„Ù…ÙˆØ¸Ù Ø§Ù„Ù…Ø¹ÙŠÙ†', 'Ø¢Ø®Ø± ØªØ­Ø¯ÙŠØ« Ø¨ÙˆØ§Ø³Ø·Ø©', 'Ø§Ù„ÙˆÙ‚Øª', 'Ø§Ù„Ù…Ù„Ù']
        pd.DataFrame(columns=req_cols).to_excel(REQUESTS_PATH, index=False, sheet_name=REQUESTS_SHEET)
        print("âœ… Created requests DB")
    else:
        print("ğŸ“‚ Excel files already exist âœ…")

# âœ… Ø§Ø³ØªØ¯Ø¹ÙÙ‡Ø§ Ù…Ø±Ø© ÙˆØ§Ø­Ø¯Ø© Ø¹Ù†Ø¯ Ø¨Ø¯Ø¡ Ø§Ù„ØªØ´ØºÙŠÙ„
ensure_excel_exists()


def normalize_columns(df):
    def clean(name):
        name = str(name).strip()
        name = name.replace("\u200f", "").replace("\u200e", "")

        # â— Ù„Ø§ Ù†ØºÙŠØ± ÙƒÙ„Ù…Ø© "Ù…Ø¤Ø±Ø´Ù" Ù†Ù‡Ø§Ø¦ÙŠØ§Ù‹
        if name.replace(" ", "") in ["Ù…Ø¤Ø±Ø´Ù", "Ù…Ø¤Ø±Ø´ÙÙ‡", "Ø§Ø±Ø´ÙŠÙ", "Ø§Ù„Ø§Ø±Ø´ÙŠÙ"]:
            return "Ù…Ø¤Ø±Ø´Ù"

        # Ø¨Ø§Ù‚ÙŠ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© ÙÙ‚Ø·
        name = name.replace("Ø¥", "Ø§").replace("Ø£", "Ø§").replace("Ø¢", "Ø§")
        name = name.replace("Ù€", "")
        name = name.replace("  ", " ")
        return name.strip()

    df.columns = [clean(c) for c in df.columns]
    return df



def load_users():
    try:
        df = pd.read_excel(DB_PATH)

        # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…ÙƒØ±Ø±Ø©
        df = remove_duplicate_columns(df)
        df = pd.read_excel(DB_PATH)

        # â­ Ø¹Ù…ÙˆØ¯ Ø¥Ø¬Ø¨Ø§Ø± ØªØºÙŠÙŠØ± ÙƒÙ„Ù…Ø© Ø§Ù„Ù…Ø±ÙˆØ± Ù„Ø£ÙˆÙ„ Ù…Ø±Ø©
        if "force_reset" not in df.columns:
            df["force_reset"] = df["force_reset"].astype(str)
            df["force_reset"] = (
                df["force_reset"]
                .str.replace(".0", "", regex=False)
                .str.replace(".00", "", regex=False)
                .str.strip()
            )

            df["force_reset"] = "1"

        # ğŸ”¹ ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ù…Ù† Ø£ÙŠ Ø±Ù…ÙˆØ² Ø£Ùˆ ÙØ±Ø§ØºØ§Øª ØºØ±ÙŠØ¨Ø©
        df.columns = (
            df.columns
            .astype(str)
            .str.replace('\u200f', '', regex=True)
            .str.replace('\u200e', '', regex=True)
            .str.replace(' ', '', regex=True)
            .str.strip()
        )

        # âœ… ØªÙˆØ­ÙŠØ¯ Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ù…Ù‡Ù…Ø§ ÙƒØ§Ù†Øª ÙƒØªØ§Ø¨ØªÙ‡Ø§
        rename_map = {
            'Ø§Ù„Ø§Ø³Ù…': 'Ø§Ù„Ø§Ø³Ù…',
            'Ø§Ù„Ø§Ø³Ù…Ø§Ù„ÙƒØ§Ù…Ù„': 'Ø§Ù„Ø§Ø³Ù…',
            'Ø§Ù„Ø§Ø³Ù…_Ø§Ù„ÙƒØ§Ù…Ù„': 'Ø§Ù„Ø§Ø³Ù…',
            'Ø§Ù„Ø§ Ø³Ù…': 'Ø§Ù„Ø§Ø³Ù…',
            'Ø§Ù„Ø¥Ø³Ù…': 'Ø§Ù„Ø§Ø³Ù…',
            'Ø§Ø³Ù…': 'Ø§Ù„Ø§Ø³Ù…',

            'Ø§Ù„Ø¨Ø±ÙŠØ¯Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠ': 'Ø§Ù„Ø¨Ø±ÙŠØ¯ Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠ',
            'Ø§Ù„Ø¨Ø±ÙŠØ¯Ø§Ù„Ø§Ù„ÙƒØªØ±ÙˆÙ†ÙŠ': 'Ø§Ù„Ø¨Ø±ÙŠØ¯ Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠ',
            'Ø§Ù„Ø¨Ø±ÙŠØ¯Ø§Ù„Ø§Ù„ÙƒØªØ±ÙˆÙ†Ù‰': 'Ø§Ù„Ø¨Ø±ÙŠØ¯ Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠ',
            'Ø§Ù„Ø§ÙŠÙ…ÙŠÙ„': 'Ø§Ù„Ø¨Ø±ÙŠØ¯ Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠ',
            'email': 'Ø§Ù„Ø¨Ø±ÙŠØ¯ Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠ',
            'Ø§ÙŠÙ…ÙŠÙ„': 'Ø§Ù„Ø¨Ø±ÙŠØ¯ Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠ',

            'Ø§Ù„Ù‚Ø³Ù…': 'Ø§Ù„Ù‚Ø³Ù…',
            'Ø§Ù„Ù‚Ø³Ù…_Ø§Ù„Ù…ÙˆØ¸Ù': 'Ø§Ù„Ù‚Ø³Ù…',
            'Ø§Ø¯Ø§Ø±Ø©': 'Ø§Ù„Ù‚Ø³Ù…',

            'Ø§Ù„ØµÙ„Ø§Ø­ÙŠÙ‡': 'Ø§Ù„ØµÙ„Ø§Ø­ÙŠØ©',
            'Ø§Ù„ÙˆØ¸ÙŠÙØ©': 'Ø§Ù„ØµÙ„Ø§Ø­ÙŠØ©',
            'role': 'Ø§Ù„ØµÙ„Ø§Ø­ÙŠØ©'
        }

        # ğŸ§© Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„ØªØ³Ù…ÙŠØ© Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„ØªØ·Ø§Ø¨Ù‚ Ø§Ù„Ø¬Ø²Ø¦ÙŠ (Ø­ØªÙ‰ Ù„Ùˆ Ù†Ø§Ù‚Øµ Ø­Ø±Ù)
        for col in list(df.columns):
            normalized = re.sub(r'[Ø¥Ø£Ø¢Ø§]', 'Ø§', col).replace(' ', '').lower()
            for k, v in rename_map.items():
                if re.sub(r'[Ø¥Ø£Ø¢Ø§]', 'Ø§', k).replace(' ', '').lower() in normalized:
                    df.rename(columns={col: v}, inplace=True)

        # âœ… Ø§Ù„ØªØ£ÙƒØ¯ Ø£Ù† ÙƒÙ„ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…Ù‡Ù…Ø© Ù…ÙˆØ¬ÙˆØ¯Ø© Ø­ØªÙ‰ Ù„Ùˆ Ù†Ø§Ù‚ØµØ©
        for col in [
            'Ø§Ù„Ø§Ø³Ù…',
            'Ø§Ù„Ø¨Ø±ÙŠØ¯ Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠ',
            'Ø§Ù„Ù‚Ø³Ù…',
            'Ø§Ù„ØµÙ„Ø§Ø­ÙŠØ©',
            'ÙƒÙ„Ù…Ø© Ø§Ù„Ù…Ø±ÙˆØ±',
            'Ø§Ù„Ø´Ø±ÙƒØ©',
            'Ø§Ù„ÙØ±Ø¹'
        ]:

            if col not in df.columns:
                df[col] = ''
        # â­ Ø¥Ø¶Ø§ÙØ© Ø¹Ù…ÙˆØ¯ Ø§Ù„Ø£Ù‚Ø³Ø§Ù… Ø§Ù„Ø£Ø®Ø±Ù‰ Ø¥Ø°Ø§ ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯
        if "Ø§Ù„Ø£Ù‚Ø³Ø§Ù… Ø§Ù„Ø£Ø®Ø±Ù‰" not in df.columns:
            df["Ø§Ù„Ø£Ù‚Ø³Ø§Ù… Ø§Ù„Ø£Ø®Ø±Ù‰"] = ""
        else:
            df["Ø§Ù„Ø£Ù‚Ø³Ø§Ù… Ø§Ù„Ø£Ø®Ø±Ù‰"] = df["Ø§Ù„Ø£Ù‚Ø³Ø§Ù… Ø§Ù„Ø£Ø®Ø±Ù‰"].astype(str).fillna("").str.strip()

        # â­ Ø¥Ø¶Ø§ÙØ© ÙˆØ¯Ø¹Ù… Ø¹Ù…ÙˆØ¯ apps (ØµÙ„Ø§Ø­ÙŠØ§Øª Ø§Ù„Ø£Ù†Ø¸Ù…Ø©)
        if "apps" not in df.columns:
            df["apps"] = ""
        else:
            df["apps"] = df["apps"].astype(str).fillna("").str.strip()

        return normalize_department_names(df)
    except Exception as e:
        print("âŒ load_users error:", e)
        return pd.DataFrame()

def get_user_all_departments():
    """Ø¥Ø±Ø¬Ø§Ø¹ ÙƒÙ„ Ø£Ù‚Ø³Ø§Ù… Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… (Ø§Ù„Ù‚Ø³Ù… Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ + Ø§Ù„Ø£Ù‚Ø³Ø§Ù… Ø§Ù„Ø£Ø®Ø±Ù‰) Ø¨Ø¹Ø¯ Ø§Ù„ØªØ·Ø¨ÙŠØ¹"""
    try:
        users_df = load_users()
        if users_df.empty:
            return []

        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ø¨Ø±ÙŠØ¯ - Ø§Ù„Ù‚Ø³Ù… - Ø§Ù„Ø£Ù‚Ø³Ø§Ù… Ø§Ù„Ø£Ø®Ø±Ù‰
        email_col = next((c for c in users_df.columns if "Ø¨Ø±ÙŠØ¯" in c or "email" in c.lower()), None)
        dept_col  = next((c for c in users_df.columns if "Ù‚Ø³Ù…" in c), None)
        extra_col = next((c for c in users_df.columns if "Ø£Ø®Ø±Ù‰" in c or "Ø§Ø®Ø±Ù‰" in c), None)

        if not email_col or not dept_col:
            return []

        # Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø§Ù„Ø­Ø§Ù„ÙŠ
        user_email = session.get("user", {}).get("email", "").strip().lower()
        users_df[email_col] = users_df[email_col].astype(str).str.lower().str.strip()

        row = users_df[users_df[email_col] == user_email]
        if row.empty:
            return []

        row = row.iloc[0]

        # -----------------------------
        # Ø§Ù„Ù‚Ø³Ù… Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ
        # -----------------------------
        all_depts = []
        main_dept = str(row.get(dept_col, "")).strip()
        if main_dept:
            all_depts.append(normalize_arabic(main_dept))

        # -----------------------------
        # Ø§Ù„Ø£Ù‚Ø³Ø§Ù… Ø§Ù„Ø£Ø®Ø±Ù‰ (Ù…Ù‚Ø³Ù…Ø© Ø¨ÙÙˆØ§ØµÙ„)
        # -----------------------------
        if extra_col:
            raw_extra = str(row.get(extra_col, "")).strip()

            if raw_extra:
                raw_extra = raw_extra.replace("\u200f", "").replace("\u200e", "")
                raw_extra = raw_extra.replace(" ØŒ", "ØŒ").replace("ØŒ ", "ØŒ")
                raw_extra = raw_extra.replace(" ,", ",").replace(", ", ",")

                raw_extra = re.sub(r"\s*,\s*", ",", raw_extra)
                raw_extra = re.sub(r"\s*ØŒ\s*", "ØŒ", raw_extra)

                raw_extra = raw_extra.replace("ØŒ", ",")

                parts = [p.strip() for p in raw_extra.split(",") if p.strip()]
                for p in parts:
                    all_depts.append(normalize_arabic(p))

        # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ØªÙƒØ±Ø§Ø±
        all_depts = list(dict.fromkeys(all_depts))

        return all_depts

    except Exception as e:
        print("get_user_all_departments error:", e)
        return []


def normalize_department_names(df):
    """ØªÙˆØ­ÙŠØ¯ Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø£Ù‚Ø³Ø§Ù… Ø¯Ø§Ø®Ù„ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ†"""
    if 'Ø§Ù„Ù‚Ø³Ù…' in df.columns:
        df['Ø§Ù„Ù‚Ø³Ù…'] = (
            df['Ø§Ù„Ù‚Ø³Ù…']
            .astype(str)
            .str.strip()
            .str.replace('\u200f','', regex=True)
            .str.replace('\u200e','', regex=True)
            .str.replace('  ',' ', regex=True)
            .str.replace('Ø§Ù„Ø§Ø¯Ø§Ø±Ø©','Ø¥Ø¯Ø§Ø±Ø©', regex=False)
        )
    return df
def remove_duplicate_columns(df):
    """Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…ÙƒØ±Ø±Ø© Ø¨Ø¹Ø¯ ØªÙ†Ø¸ÙŠÙÙ‡Ø§"""
    seen = set()
    new_cols = []
    drop_idx = []

    for idx, col in enumerate(df.columns):
        clean = (
            str(col)
            .strip()
            .replace("\u200f", "")
            .replace("\u200e", "")
        )
        clean = re.sub(r"[Ø¥Ø£Ø¢Ø§]", "Ø§", clean)

        if clean in seen:
            drop_idx.append(idx)
        else:
            seen.add(clean)
            new_cols.append(col)

    # Ø­Ø°Ù Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…ÙƒØ±Ø±Ø©
    if drop_idx:
        df = df.drop(df.columns[drop_idx], axis=1)

    return df

def load_requests():
    try:
        if not os.path.exists(REQUESTS_PATH):
            return pd.DataFrame()

        df = pd.read_excel(REQUESTS_PATH, dtype=str)

        # ============================================================
        # 1) Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…ÙƒØ±Ø±Ø© (Ù‚Ø¨Ù„ Ø£ÙŠ Ø´ÙŠØ¡)
        # ============================================================
        df = remove_duplicate_columns(df)

        # ============================================================
        # 2) ØªÙ†Ø¸ÙŠÙ Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ù…Ù† Ø§Ù„Ù…Ø­Ø§Ø±Ù Ø§Ù„Ø®ÙÙŠØ©
        # ============================================================
        df.columns = (
            df.columns
            .str.strip()
            .str.replace("\u200f", "")
            .str.replace("\u200e", "")
        )

        # ============================================================
        # 3) Ø®Ø±ÙŠØ·Ø© ØªÙˆØ­ÙŠØ¯ Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©
        # ============================================================
        rename_map = {
            "Ø§Ù„Ø­Ø§Ù„Ù‡": "Ø§Ù„Ø­Ø§Ù„Ø©",
            "Ø§Ø®Ø± ØªØ­Ø¯ÙŠØ« Ø¨ÙˆØ§Ø³Ø·Ù‡": "Ø¢Ø®Ø± ØªØ­Ø¯ÙŠØ« Ø¨ÙˆØ§Ø³Ø·Ø©",
            "Ø§Ø®Ø± ØªØ­Ø¯ÙŠØ« Ø¨ÙˆØ§Ø³Ø·Ø©": "Ø¢Ø®Ø± ØªØ­Ø¯ÙŠØ« Ø¨ÙˆØ§Ø³Ø·Ø©",
            "Ø§Ø®Ø± ØªØ­Ø¯ÙŠØ«": "Ø¢Ø®Ø± ØªØ­Ø¯ÙŠØ« Ø¨ÙˆØ§Ø³Ø·Ø©",
            "Ø¨Ø¯Ø§ Ø§Ù„ØªÙ†ÙÙŠØ° Ø¨ÙˆØ§Ø³Ø·Ù‡": "Ø¨Ø¯Ø£ Ø§Ù„ØªÙ†ÙÙŠØ° Ø¨ÙˆØ§Ø³Ø·Ø©",
            "Ø§ØºÙ„Ù‚ Ø¨ÙˆØ§Ø³Ø·Ù‡": "Ø£ØºÙ„Ù‚ Ø¨ÙˆØ§Ø³Ø·Ø©",
            "Ø§Ù„Ù‚Ø³Ù… Ø§Ù„Ù…Ø³ØªÙ„Ù… ": "Ø§Ù„Ù‚Ø³Ù… Ø§Ù„Ù…Ø³ØªÙ„Ù…",
            "Ø§Ù„Ù‚Ø³Ù… Ø§Ù„Ù…Ø±Ø³Ù„ ": "Ø§Ù„Ù‚Ø³Ù… Ø§Ù„Ù…Ø±Ø³Ù„",
        }

        for old, new in rename_map.items():
            if old in df.columns:
                df.rename(columns={old: new}, inplace=True)

        # ============================================================
        # 4) Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…ÙƒØ±Ø±Ø© Ù…Ø±Ø© Ø«Ø§Ù†ÙŠØ© Ø¨Ø¹Ø¯ Ø§Ù„Ø¯Ù…Ø¬
        # ============================================================
        df = df.loc[:, ~df.columns.duplicated()]

        # ============================================================
        # 5) ØªÙ†Ø¸ÙŠÙ Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ø®Ù„Ø§ÙŠØ§
        # ============================================================
        df = df.applymap(lambda x: x.strip() if isinstance(x, str) else x)

        # ============================================================
        # 6) Ø¶Ù…Ø§Ù† ÙˆØ¬ÙˆØ¯ Ø¹Ù…ÙˆØ¯ "Ù…Ø¤Ø±Ø´Ù"
        # ============================================================
        if "Ù…Ø¤Ø±Ø´Ù" not in df.columns:
            df["Ù…Ø¤Ø±Ø´Ù"] = "0"

        df["Ù…Ø¤Ø±Ø´Ù"] = df["Ù…Ø¤Ø±Ø´Ù"].astype(str).apply(
            lambda x: "1" if str(x).strip().lower() in ["1", "Ù†Ø¹Ù…", "true", "yes", "y"] else "0"
        )

        return df

    except Exception as e:
        print("load_requests error:", e)
        return pd.DataFrame()

def save_requests(df):
    # 1) Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…ÙƒØ±Ø±Ø© Ù‚Ø¨Ù„ Ø£ÙŠ Ø´ÙŠØ¡
    df = remove_duplicate_columns(df)

    # 2) ØªØ·Ø¨ÙŠØ¹ Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©
    df = normalize_columns(df)

    # 3) Ø®Ø±ÙŠØ·Ø© ØªØµØ­ÙŠØ­ Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ù„Ù…Ù†Ø¹ ØªÙƒØ±Ø§Ø±Ù‡Ø§
    rename_map = {
        "Ø§Ù„Ø­Ø§Ù„Ù‡": "Ø§Ù„Ø­Ø§Ù„Ø©",
        "Ø§Ø®Ø± ØªØ­Ø¯ÙŠØ« Ø¨ÙˆØ§Ø³Ø·Ù‡": "Ø¢Ø®Ø± ØªØ­Ø¯ÙŠØ« Ø¨ÙˆØ§Ø³Ø·Ø©",
        "Ø§Ø®Ø± ØªØ­Ø¯ÙŠØ« Ø¨ÙˆØ§Ø³Ø·Ø©": "Ø¢Ø®Ø± ØªØ­Ø¯ÙŠØ« Ø¨ÙˆØ§Ø³Ø·Ø©",
        "Ø¨Ø¯Ø§ Ø§Ù„ØªÙ†ÙÙŠØ° Ø¨ÙˆØ§Ø³Ø·Ù‡": "Ø¨Ø¯Ø£ Ø§Ù„ØªÙ†ÙÙŠØ° Ø¨ÙˆØ§Ø³Ø·Ø©",
        "Ø§ØºÙ„Ù‚ Ø¨ÙˆØ§Ø³Ø·Ù‡": "Ø£ØºÙ„Ù‚ Ø¨ÙˆØ§Ø³Ø·Ø©",
        "Ø§Ù„Ù‚Ø³Ù… Ø§Ù„Ù…Ø±Ø³Ù„ ": "Ø§Ù„Ù‚Ø³Ù… Ø§Ù„Ù…Ø±Ø³Ù„",
        "Ø§Ù„Ù‚Ø³Ù… Ø§Ù„Ù…Ø³ØªÙ„Ù… ": "Ø§Ù„Ù‚Ø³Ù… Ø§Ù„Ù…Ø³ØªÙ„Ù…",
    }

    for old, new in rename_map.items():
        if old in df.columns:
            df.rename(columns={old: new}, inplace=True)

    # 4) Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…ÙƒØ±Ø±Ø© Ù…Ø±Ø© Ø«Ø§Ù†ÙŠØ© Ø¨Ø¹Ø¯ Ø§Ù„ØªÙˆØ­ÙŠØ¯
    df = df.loc[:, ~df.columns.duplicated()]

    # 5) Ø§Ù„ØªØ£ÙƒØ¯ Ø£Ù† ÙƒÙ„ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© Ù…ÙˆØ¬ÙˆØ¯Ø©
    required_cols = [
        'Ø±Ù‚Ù… Ø§Ù„Ø·Ù„Ø¨', 'Ø§Ù„ØªØ§Ø±ÙŠØ®', 'Ø§Ù„Ø¹Ù†ÙˆØ§Ù†', 'Ø§Ù„ÙˆØµÙ',
        'Ø§Ù„Ù‚Ø³Ù… Ø§Ù„Ù…Ø±Ø³Ù„', 'Ø§Ù„Ù‚Ø³Ù… Ø§Ù„Ù…Ø³ØªÙ„Ù…', 'Ø§Ù„Ø­Ø§Ù„Ø©',
        'Ø§Ù„Ù…ÙˆØ¸Ù Ø§Ù„Ù…Ø¹ÙŠÙ†', 'Ø¢Ø®Ø± ØªØ­Ø¯ÙŠØ« Ø¨ÙˆØ§Ø³Ø·Ø©',
        'Ø¨Ø¯Ø£ Ø§Ù„ØªÙ†ÙÙŠØ° Ø¨ÙˆØ§Ø³Ø·Ø©', 'Ø£ØºÙ„Ù‚ Ø¨ÙˆØ§Ø³Ø·Ø©',
        'Ø§Ù„ÙˆÙ‚Øª', 'Ø§Ù„Ù…Ù„Ù',
        'Ø§Ø³Ù… Ø§Ù„Ù…Ø±Ø³Ù„', 'Ø§Ø³Ù… Ø§Ù„Ù…Ø³ØªÙ„Ù…',
        'Ù…Ø¤Ø±Ø´Ù'
    ]

    for col in required_cols:
        if col not in df.columns:
            df[col] = ""

    # 6) ØªØ±ØªÙŠØ¨ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø¨Ù†ÙØ³ ØªØ±ØªÙŠØ¨ required_cols Ù„Ù…Ù†Ø¹ Ø£ÙŠ ÙÙˆØ¶Ù‰
    df = df[required_cols]

    # 7) Ø­ÙØ¸ Ø§Ù„Ù…Ù„Ù Ø¨Ø¯ÙˆÙ† Ø¥Ø¹Ø§Ø¯Ø© Ø¥Ù†ØªØ§Ø¬ Ø£Ø¹Ù…Ø¯Ø© Ù…ÙƒØ±Ø±Ø©
    df.to_excel(REQUESTS_PATH, index=False, sheet_name=REQUESTS_SHEET)

def generate_request_id():
    df = load_requests()
    if df.empty or 'Ø±Ù‚Ù… Ø§Ù„Ø·Ù„Ø¨' not in df.columns or df['Ø±Ù‚Ù… Ø§Ù„Ø·Ù„Ø¨'].dropna().empty:
        return f"REQ-{datetime.now().year}-001"
    try:
        last_id = str(df['Ø±Ù‚Ù… Ø§Ù„Ø·Ù„Ø¨'].dropna().iloc[-1])
        number = int(last_id.split('-')[-1]) + 1
        return f"REQ-{datetime.now().year}-{number:03}"
    except:
        return f"REQ-{datetime.now().year}-001"

# ============== Ø§Ù„ØµÙØ­Ø§Øª ==============
@app.route('/')
def index(): return render_template('Login.html')

@app.route('/Login.html')
def login_page(): return render_template('Login.html')

@app.route('/EmployeePage.html')
def emp_page(): return render_template('EmployeePage.html')

@app.route('/DepartmentManagerPage.html')
def mgr_page(): return render_template('DepartmentManagerPage.html')

@app.route('/GeneralManager.html')
def gm_page(): return render_template('GeneralManager.html')
@app.route('/HrPage.html')
def hr_page():
    return render_template('HrPage.html')
@app.route('/ForgotYourPassword.html')
def forgot_page(): return render_template('ForgotYourPassword.html')

@app.route('/Portal.html')
def portal_page():
    return render_template('Portal.html')


@app.route("/api/portal/apps")
def portal_apps():
    user = session.get("user")
    if not user:
        return jsonify({"apps": []})

    return jsonify({
        "apps": user.get("apps", [])
    })


@app.route('/admin.html')
def admin_page():
    return render_template('admin.html')
# ============== API: Ø§Ù„Ø¯Ø®ÙˆÙ„ ==============
def normalize_role(text):
    if not isinstance(text, str):
        text = str(text)

    t = text.strip()
    t = re.sub(r'[Ø¥Ø£Ø¢Ø§]', 'Ø§', t)
    t = t.replace('Ø©', 'Ù‡')
    t = t.replace('  ', '')
    t = t.replace('â€“', '-').replace('_', '').replace('/', '')
    t = t.replace('Ø§Ù„', '')
    t = t.replace(' ', '').lower()

    # Ù…Ø¯ÙŠØ± Ø¹Ø§Ù…
    if t in ["Ù…Ø¯ÙŠØ±Ø¹Ø§Ù…", "Ù…Ø¯ÙŠØ±Ø¹Ø§Ù…Ù‡", "Ø¬Ù†Ø±Ø§Ù„", "generalmanager", "gm"]:
        return "general_manager"

    # Ù…Ø¯ÙŠØ± Ù‚Ø³Ù…
    if any(x in t for x in [
        "Ù…Ø¯ÙŠØ±Ù‚Ø³Ù…",
        "Ù…Ø¯ÙŠØ±Ø§Ù„Ù‚Ø³Ù…",
        "Ø±Ø¦ÙŠØ³Ù‚Ø³Ù…",
        "manager",
        "head",
    ]):
        return "manager"

    # Ø§Ù„Ù…ÙˆØ§Ø±Ø¯ Ø§Ù„Ø¨Ø´Ø±ÙŠØ©

    if any(x in t for x in [
        "Ù…ÙˆØ§Ø±Ø¯Ø¨Ø´Ø±ÙŠÙ‡",
        "Ù…ÙˆØ§Ø±Ø¯Ø¨Ø´Ø±ÙŠØ©",
        "Ø§Ù„Ù…ÙˆØ§Ø±Ø¯Ø§Ù„Ø¨Ø´Ø±ÙŠÙ‡",
        "Ø§Ù„Ù…ÙˆØ§Ø±Ø¯Ø§Ù„Ø¨Ø´Ø±ÙŠØ©",
        "hr",
        "humanresource"
    ]):
        return "hr"

    # Ø£Ø¯Ù…Ù†
    if t in ["Ø§Ø¯Ù…Ù†", "admin", "Ù…Ø´Ø±Ù", "Ù…Ø¯ÙŠØ±Ù†Ø¸Ø§Ù…"]:
        return "admin"

    # Ù…ÙˆØ¸Ù
    if t in ["Ù…ÙˆØ¸Ù", "Ø¹Ø§Ù…Ù„", "staff", "employee"]:
        return "employee"

    return t


from flask import session
app.secret_key = "SEVENS-SECRET-2025"

@app.route('/api/auth/session_check', methods=['GET'])
def session_check():
    """ÙŠØªØ£ÙƒØ¯ Ø£Ù† Ø§Ù„Ø¬Ù„Ø³Ø© ØµØ­ÙŠØ­Ø© Ø¨Ø¹Ø¯ Ø£ÙŠ ØªØ¹Ø¯ÙŠÙ„"""
    user = session.get("user")
    if not user:
        return jsonify({"valid": False})

    df = load_users()

    email_col = next((c for c in df.columns if "Ø¨Ø±ÙŠØ¯" in c or "email" in c.lower()), None)
    role_col  = next((c for c in df.columns if "ØµÙ„Ø§Ø­" in c or "role" in c.lower()), None)
    dept_col  = next((c for c in df.columns if "Ù‚Ø³Ù…" in c), None)
    name_col  = next((c for c in df.columns if "Ø§Ø³Ù…" in c), None)
    status_col= next((c for c in df.columns if "Ø­Ø§Ù„" in c), None)

    df[email_col] = df[email_col].astype(str).str.lower().str.strip()
    row = df[df[email_col] == user["email"]]

    if row.empty:
        session.clear()
        return jsonify({"valid": False})

    row = row.iloc[0]

    # ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„ØªØºÙŠÙŠØ±Ø§Øª
    new_role = normalize_role(str(row[role_col]))
    new_dept = str(row[dept_col]).strip()
    new_name = str(row[name_col]).strip()
    new_status = str(row.get(status_col, "Ù†Ø´Ø·")).strip()

    # Ù„Ùˆ ØªØºÙŠÙ‘Ø±Øª Ø§Ù„ØµÙ„Ø§Ø­ÙŠØ© Ø£Ùˆ Ø§Ù„Ù‚Ø³Ù… â†’ Ø³Ø¬Ù„ Ø®Ø±ÙˆØ¬
    # Normalize Ù„Ù„Ø·Ø±ÙÙŠÙ† Ù‚Ø¨Ù„ Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø©
    old_role = user["role_raw"]
    old_dept = normalize_arabic(user["department"])

    new_role_norm = normalize_role(new_role)
    new_dept_norm = normalize_arabic(new_dept)

    # Ø¥Ø°Ø§ Ø§Ø®ØªÙ„ÙØª Ø§Ù„ØµÙ„Ø§Ø­ÙŠØ© Ø£Ùˆ Ø§Ù„Ù‚Ø³Ù… Ø¨Ø¹Ø¯ Ø§Ù„ØªØ·Ø¨ÙŠØ¹
    if old_role != new_role_norm or old_dept != new_dept_norm:
        session.clear()
        return jsonify({"valid": False})

    if new_status != "Ù†Ø´Ø·":
        session.clear()
        return jsonify({"valid": False})

    # â­ Ø¥Ø¹Ø§Ø¯Ø© Ø¬Ù„Ø¨ force_reset
    force_raw = str(row.get("force_reset", "0"))
    force_raw = force_raw.replace(".0", "").replace(".00", "").strip()

    force_reset_needed = (force_raw not in ["0"])

    return jsonify({
        "valid": True,
        "user": session.get("user")
    })


@app.route('/api/login', methods=['POST'])
def login():
    data = request.get_json() or {}
    email = (data.get('email', '') or '').strip().lower()
    password = (data.get('password', '') or '').strip()

    df = load_users()
    if df.empty:
        return jsonify({"success": False, "message": "Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ† ÙØ§Ø±ØºØ©"}), 500

    # ==== Ø§ÙƒØªØ´Ø§Ù Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© ====
    email_col = next((c for c in df.columns if 'Ø¨Ø±ÙŠØ¯' in c or 'email' in c.lower()), None)
    pass_col  = next((c for c in df.columns if 'Ù…Ø±ÙˆØ±' in c or 'pass' in c.lower()), None)
    role_col  = next((c for c in df.columns if 'ØµÙ„Ø§Ø­' in c or 'role' in c.lower()), None)
    dept_col  = next((c for c in df.columns if 'Ù‚Ø³Ù…' in c), None)
    name_col  = next((c for c in df.columns if 'Ø§Ø³Ù…' in c), None)
    company_col = next((c for c in df.columns if "Ø´Ø±ÙƒØ©" in c), None)
    branch_col = next((c for c in df.columns if "ÙØ±Ø¹" in c), None)

    # ==== ØªÙ†Ø¸ÙŠÙ ====
    df[email_col] = df[email_col].astype(str).str.lower().str.strip()
    df[pass_col]  = df[pass_col].astype(str).str.strip()

    # ==== Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø© ====
    user = df[(df[email_col] == email) & (df[pass_col] == password)]
    if user.empty:
        return jsonify({"success": False, "message": "Ø§Ù„Ø¨Ø±ÙŠØ¯ Ø£Ùˆ ÙƒÙ„Ù…Ø© Ø§Ù„Ù…Ø±ÙˆØ± ØºÙŠØ± ØµØ­ÙŠØ­Ø©"}), 401

    user = user.iloc[0]

    raw_role = str(user[role_col]).strip()
    dept_raw = str(user.get(dept_col, '')).strip()
    name     = str(user.get(name_col, '')).strip()
    company = str(user.get(company_col, '')).strip() if company_col else ""
    branch = str(user.get(branch_col, '')).strip() if branch_col else ""

    # ==== Normalize ====
    dept_norm = normalize_arabic(dept_raw)
    role_norm = normalize_role(raw_role)

    # ==== ØªÙˆØ¬ÙŠÙ‡ Ù…ÙˆØ­Ø¯ Ø¥Ù„Ù‰ Ø§Ù„Ø¨ÙˆØ§Ø¨Ø© ÙÙ‚Ø· ====
    role = role_norm
    redirect = "Portal.html"

    # ==== Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ø£Ù‚Ø³Ø§Ù… Ø§Ù„Ø£Ø®Ø±Ù‰ Extra Departments ====
    extra_col = next((c for c in df.columns if "Ø£Ø®Ø±Ù‰" in c or "Ø§Ø®Ø±Ù‰" in c), None)
    extra_depts = []

    if extra_col:
        raw_extra = str(user.get(extra_col, "")).strip()

        if raw_extra:
            # ğŸ”¥ Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø±Ù…ÙˆØ² Ø§Ù„Ø®ÙÙŠØ©
            raw_extra = raw_extra.replace("\u200f", "").replace("\u200e", "")

            # ğŸ”¥ ØªÙˆØ­ÙŠØ¯ Ø§Ù„ÙÙˆØ§ØµÙ„ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© ÙˆØ§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©
            raw_extra = raw_extra.replace(" ØŒ", "ØŒ").replace("ØŒ ", "ØŒ")
            raw_extra = raw_extra.replace(" ,", ",").replace(", ", ",")

            # ğŸ”¥ Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ù…Ø³Ø§ÙØ§Øª Ø­ÙˆÙ„ Ø§Ù„ÙÙˆØ§ØµÙ„
            raw_extra = re.sub(r"\s*,\s*", ",", raw_extra)
            raw_extra = re.sub(r"\s*ØŒ\s*", "ØŒ", raw_extra)

            # ğŸ”¥ Ø§Ø³ØªØ¨Ø¯Ø§Ù„ Ø§Ù„ÙØ§ØµÙ„Ø© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø¨Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ© (Ø§Ø®ØªÙŠØ§Ø±ÙŠ Ù„Ù„ØªØ³Ù‡ÙŠÙ„)
            raw_extra = raw_extra.replace("ØŒ", ",")

            # ğŸ”¥ ØªÙ‚Ø³ÙŠÙ… Ù…Ø¶Ù…ÙˆÙ† 100%
            parts = [p.strip() for p in raw_extra.split(",") if p.strip()]

            extra_depts = [normalize_arabic(p) for p in parts]
        else:
            extra_depts = []

    # ==== Ø¨Ù†Ø§Ø¡ session ====
    session["user"] = {
        "email": email,
        "name": name,
        "role": role,
        "role_raw": role_norm,
        "department": dept_norm,
        "company": company,
        "branch": branch,
        "extra_departments": extra_depts
    }

    apps_raw = str(user.get("apps", "")).strip().lower()

    # ğŸ”¥ Ù…Ø¹Ø§Ù„Ø¬Ø© NaN / None Ø¨Ø´ÙƒÙ„ ØµØ±ÙŠØ­
    if apps_raw in ["nan", "none", "null"]:
        apps_raw = ""

    apps_list = [a.strip() for a in apps_raw.split(",") if a.strip()]
    session["user"]["apps"] = apps_list

    # =====================================================
    #                FORCE RESET â€” Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ø³Ù„ÙŠÙ…Ø©
    # =====================================================
    force_raw = str(user.get("force_reset", "0")).strip()
    force_raw = force_raw.replace(".0", "").replace(".00", "").strip()

    # Ø§Ù„Ù‚ÙŠÙ…Ø© Ø§Ù„ØµØ­ÙŠØ­Ø© Ø§Ù„ÙˆØ­ÙŠØ¯Ø© Ù„Ø¥Ø¬Ø¨Ø§Ø± Ø§Ù„ØªØºÙŠÙŠØ± Ù‡ÙŠ 1 ÙÙ‚Ø·
    needs_reset = (force_raw == "1")

    session["user"]["force_reset"] = needs_reset

    # =====================================================

    return jsonify({
        "success": True,
        "redirect": redirect,
        "user": {
    "email": email,
    "name": name,
    "role": role,
    "department": dept_norm,
    "company": company,
    "branch": branch,
    "apps": str(user.get("apps", "")),
    "force_reset": needs_reset,
    "extra_departments": extra_depts
}

    })

@app.route("/api/session")
def api_session():
    user = session.get("user")
    if not user:
        return jsonify({"error": "no session"}), 401
    return jsonify(user)

@app.route('/api/admin/check', methods=['POST'])
def admin_check():
    """Ø§Ù„ØªØ­Ù‚Ù‚ Ù‡Ù„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø£Ø¯Ù…Ù†"""
    data = request.get_json() or {}
    role = data.get('role', '').strip().lower()

    if 'admin' in role or 'Ø§Ø¯Ù…Ù†' in normalize_arabic(role):
        return jsonify({"admin": True})

    return jsonify({"admin": False})


@app.route('/api/admin/get_info', methods=['POST'])
def admin_info():
    data = request.get_json() or {}
    email = (data.get('email') or '').strip().lower()

    df = load_users()
    if df.empty:
        return jsonify({"success": False, "error": "ÙØ´Ù„ ØªØ­Ù…ÙŠÙ„ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ†"}), 500

    # ğŸ” Ø§ÙƒØªØ´Ø§Ù Ø§Ø³Ù… Ø¹Ù…ÙˆØ¯ Ø§Ù„Ø¨Ø±ÙŠØ¯ Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠ Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠÙ‹Ø§ (Ù…Ø«Ù„ login)
    email_col = next((c for c in df.columns if any(k in str(c).lower() for k in ['Ø¨Ø±ÙŠØ¯', 'email', 'Ø§ÙŠÙ…ÙŠÙ„'])), None)

    if not email_col:
        return jsonify({"success": False, "error": "Ø¹Ù…ÙˆØ¯ Ø§Ù„Ø¨Ø±ÙŠØ¯ Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠ ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯ ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"}), 500

    # âœ… Ø§Ù„ØªÙ†Ø¸ÙŠÙ ÙˆØ§Ù„Ø¨Ø­Ø«
    df[email_col] = df[email_col].astype(str).str.lower().str.strip()
    user_row = df[df[email_col] == email]

    if user_row.empty:
        return jsonify({"success": False, "message": "Ù„Ù… ÙŠÙØ¹Ø«Ø± Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…"})

    user = user_row.iloc[0].to_dict()
    # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù‚ÙŠÙ… Ø¥Ù„Ù‰ Ù†Øµ Ù„ØªØ¬Ù†Ø¨ Ù…Ø´Ø§ÙƒÙ„ JSON (Ù…Ø«Ù„ NaN)
    user = {str(k): str(v) if pd.notna(v) else '' for k, v in user.items()}

    return jsonify({"success": True, "user": user})

# ============== API: Ø¬Ù„Ø¨ Ø§Ù„Ù…ÙˆØ¸ÙÙŠÙ† Ù„ÙƒÙ„ Ù‚Ø³Ù… ==============
@app.route('/api/get_employees', methods=['POST'])
def get_employees():
    """
    Ø¬Ù„Ø¨ Ø§Ù„Ù…ÙˆØ¸ÙÙŠÙ† Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø¯ÙŠØ± (ÙƒÙ„ Ø§Ù„Ù…ÙˆØ¸ÙÙŠÙ† Ø§Ù„ØªØ§Ø¨Ø¹ÙŠÙ† Ù„Ù‡ Ø¨ØºØ¶ Ø§Ù„Ù†Ø¸Ø± Ø¹Ù† Ø§Ù„Ù‚Ø³Ù…)
    """
    try:
        data = request.get_json() or {}
        manager_name = (data.get('manager_name', '') or '').strip()
        dept = (data.get('department', '') or '').strip()

        df = load_users()
        if df.empty:
            return jsonify({"success": False, "message": "Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ†"})

        # ğŸ”¹ Ø§ÙƒØªØ´Ø§Ù Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©
        name_col = next((c for c in df.columns if 'Ø§Ø³Ù…' in str(c)), 'Ø§Ù„Ø§Ø³Ù…')
        role_col = next((c for c in df.columns if 'ØµÙ„Ø§Ø­' in str(c)), 'Ø§Ù„ØµÙ„Ø§Ø­ÙŠØ©')
        dept_col = next((c for c in df.columns if 'Ù‚Ø³Ù…' in str(c)), 'Ø§Ù„Ù‚Ø³Ù…')

        df['Ø§Ù„Ø§Ø³Ù…'] = df[name_col].astype(str).str.strip()
        df['Ø§Ù„ØµÙ„Ø§Ø­ÙŠØ©'] = df[role_col].astype(str).str.strip()
        df['Ø§Ù„Ù‚Ø³Ù…'] = df[dept_col].astype(str).str.strip()

        # âœ… Ø§Ù„Ù…Ù†Ø·Ù‚ Ø§Ù„Ø¬Ø¯ÙŠØ¯:
        # Ø¥Ø°Ø§ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ù…Ø¯ÙŠØ± Ù‚Ø³Ù… â†’ ÙŠØ´ÙˆÙ ÙƒÙ„ Ø§Ù„Ù…ÙˆØ¸ÙÙŠÙ† Ø§Ù„Ù„ÙŠ ØµÙ„Ø§Ø­ÙŠØªÙ‡Ù… "Ù…ÙˆØ¸Ù"
        if manager_name:
            df = df[df['Ø§Ù„ØµÙ„Ø§Ø­ÙŠØ©'].isin(['Ù…ÙˆØ¸Ù', 'Ø¹Ø§Ù…Ù„'])]

        # âœ… Ø§Ù„Ù…Ø¯ÙŠØ± Ø§Ù„Ø¹Ø§Ù… ÙŠØ´ÙˆÙ Ø§Ù„ÙƒÙ„
        employees = df[['Ø§Ù„Ø§Ø³Ù…', 'Ø§Ù„Ù‚Ø³Ù…', 'Ø§Ù„ØµÙ„Ø§Ø­ÙŠØ©']].dropna().to_dict(orient='records')
        return jsonify({"success": True, "employees": employees})

    except Exception as e:
        print("âŒ get_employees error:", e)
        return jsonify({"success": False, "message": str(e)})


# ============== API: Ø§Ù„Ø·Ù„Ø¨Ø§Øª ==============
@app.route('/api/get_requests', methods=['POST'])
def get_requests():
    try:
        # ================================
        # 1) Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ù…Ù† Ø§Ù„Ø¬Ù„Ø³Ø©
        # ================================
        user = session.get("user")
        if not user:
            return jsonify([])

        role = user.get("role", "")
        user_name = normalize_arabic(user.get("name", "")).replace(" ", "")


        # Ù…Ù† Ø§Ù„Ø¬Ù„Ø³Ø©
        main_dept = normalize_arabic(user.get("department", ""))
        extra_depts = [normalize_arabic(x) for x in (user.get("extra_departments") or [])]

        # ================================
        # 2) Ø¯Ù…Ø¬ Ø§Ù„Ø£Ù‚Ø³Ø§Ù… Ø§Ù„Ù‚Ø§Ø¯Ù…Ø© Ø¹Ø¨Ø± POST
        # ================================
        data = request.get_json(silent=True) or {}
        posted_depts = data.get("departments", [])
        posted_depts = [normalize_arabic(str(d)).strip() for d in posted_depts if d]


        # ØªØ¬Ù…ÙŠØ¹ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø£Ù‚Ø³Ø§Ù… Ø¨Ø¯ÙˆÙ† ØªÙƒØ±Ø§Ø±
        user_departments = list({main_dept, *extra_depts, *posted_depts})

        # ================================
        # 3) ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø·Ù„Ø¨Ø§Øª
        # ================================
        df = load_requests()
        if df.empty:
            return jsonify([])

        df = df.loc[:, ~df.columns.duplicated()]

        # ØªØ·Ø¨ÙŠØ¹ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©
        df["Ø§Ù„Ù‚Ø³Ù… Ø§Ù„Ù…Ø±Ø³Ù„"] = df["Ø§Ù„Ù‚Ø³Ù… Ø§Ù„Ù…Ø±Ø³Ù„"].astype(str).apply(normalize_arabic)
        df["Ø§Ù„Ù‚Ø³Ù… Ø§Ù„Ù…Ø³ØªÙ„Ù…"] = df["Ø§Ù„Ù‚Ø³Ù… Ø§Ù„Ù…Ø³ØªÙ„Ù…"].astype(str).apply(normalize_arabic)
        df["Ø§Ø³Ù… Ø§Ù„Ù…Ø±Ø³Ù„_norm"] = df["Ø§Ø³Ù… Ø§Ù„Ù…Ø±Ø³Ù„"].astype(str).apply(
            lambda x: normalize_arabic(x)
        )

        # ================================
        # 4) Ø¯Ø§Ù„Ø© Ù…Ø·Ø§Ø¨Ù‚Ø© Ø§Ù„Ø£Ù‚Ø³Ø§Ù…
        # ================================
        def dept_match(req_dept):
            req_dept = normalize_arabic(req_dept)
            for d in user_departments:
                d = normalize_arabic(d)
                if req_dept == d or req_dept in d or d in req_dept:
                    return True
            return False

        # ================================
        # 5) Ø§Ø³ØªØ¨Ø¹Ø§Ø¯ Ø§Ù„Ù…Ø¤Ø±Ø´Ù + ØµÙ„Ø§Ø­ÙŠØ§Øª Ø§Ù„ÙˆØµÙˆÙ„
        # ================================
        role_norm = normalize_role(role)

        # âœ… Ø§Ø³ØªØ¨Ø¹Ø§Ø¯ Ø§Ù„Ø·Ù„Ø¨Ø§Øª Ø§Ù„Ù…Ø¤Ø±Ø´ÙØ© Ù…Ù† Ø¬Ù…ÙŠØ¹ Ø§Ù„ØµÙØ­Ø§Øª Ù…Ø§ Ø¹Ø¯Ø§ ØµÙØ­Ø© Ø§Ù„Ø£Ø¯Ù…Ù†
        if "Ù…Ø¤Ø±Ø´Ù" in df.columns and role_norm != "admin":
            df["Ù…Ø¤Ø±Ø´Ù"] = df["Ù…Ø¤Ø±Ø´Ù"].astype(str).str.strip()
            df = df[df["Ù…Ø¤Ø±Ø´Ù"] != "1"]

        if role_norm == "employee":
            incoming = df[df["Ø§Ù„Ù‚Ø³Ù… Ø§Ù„Ù…Ø³ØªÙ„Ù…"].apply(dept_match)]
            outgoing = df[df["Ø§Ø³Ù… Ø§Ù„Ù…Ø±Ø³Ù„_norm"] == normalize_arabic(user.get("name", ""))]
            result = pd.concat([incoming, outgoing]).drop_duplicates()

        elif role_norm == "manager":
            incoming = df[df["Ø§Ù„Ù‚Ø³Ù… Ø§Ù„Ù…Ø³ØªÙ„Ù…"].apply(dept_match)]
            outgoing = df[df["Ø§Ù„Ù‚Ø³Ù… Ø§Ù„Ù…Ø±Ø³Ù„"].apply(dept_match)]
            result = pd.concat([incoming, outgoing]).drop_duplicates()

        elif role_norm in ["general_manager", "admin", "hr"]:
            result = df.copy()

        else:
            result = pd.DataFrame()

        return jsonify(result.fillna('').to_dict(orient='records'))

    except Exception as e:
        print("âŒ get_requests error:", e)
        return jsonify([])


@app.route('/api/create_request', methods=['POST'])
def create_request():
    try:
        title  = request.form.get('title', '').strip()
        desc   = request.form.get('description', '').strip()
        target = request.form.get('targetDept', '').strip()
        sender = request.form.get('senderDept', '').strip()
        sender_name = request.form.get('senderName', '').strip()

        file = request.files.get('file')

        if not all([title, desc, target, sender]):
            return jsonify({"success": False, "message": "Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø­Ù‚ÙˆÙ„ Ù…Ø·Ù„ÙˆØ¨Ø©"}), 400

        df = load_requests()
        for col in ['Ø±Ù‚Ù… Ø§Ù„Ø·Ù„Ø¨','Ø§Ù„ØªØ§Ø±ÙŠØ®','Ø§Ù„Ø¹Ù†ÙˆØ§Ù†','Ø§Ù„ÙˆØµÙ','Ø§Ù„Ù‚Ø³Ù… Ø§Ù„Ù…Ø±Ø³Ù„','Ø§Ù„Ù‚Ø³Ù… Ø§Ù„Ù…Ø³ØªÙ„Ù…',
                    'Ø§Ù„Ø­Ø§Ù„Ø©','Ø§Ù„Ù…ÙˆØ¸Ù Ø§Ù„Ù…Ø¹ÙŠÙ†','Ø¢Ø®Ø± ØªØ­Ø¯ÙŠØ« Ø¨ÙˆØ§Ø³Ø·Ø©','Ø§Ù„ÙˆÙ‚Øª','Ø¨Ø¯Ø£ Ø§Ù„ØªÙ†ÙÙŠØ° Ø¨ÙˆØ§Ø³Ø·Ø©','Ø£ØºÙ„Ù‚ Ø¨ÙˆØ§Ø³Ø·Ø©','Ø§Ù„Ù…Ù„Ù']:
            if col not in df.columns:
                df[col] = ""

        req_id = generate_request_id()
        file_name = ""
        if file:
            safe_name = f"{req_id}_{file.filename}"
            file_path = os.path.join(UPLOAD_DIR, safe_name)
            file.save(file_path)
            file_name = safe_name

        new_row = {
            'Ø±Ù‚Ù… Ø§Ù„Ø·Ù„Ø¨': req_id,
            'Ø§Ù„ØªØ§Ø±ÙŠØ®': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            'Ø§Ù„Ø¹Ù†ÙˆØ§Ù†': title,
            'Ø§Ù„ÙˆØµÙ': desc,
            'Ø§Ù„Ù‚Ø³Ù… Ø§Ù„Ù…Ø±Ø³Ù„': sender,
            'Ø§Ø³Ù… Ø§Ù„Ù…Ø±Ø³Ù„': sender_name,
            'Ø§Ù„Ù‚Ø³Ù… Ø§Ù„Ù…Ø³ØªÙ„Ù…': target,
            'Ø§Ø³Ù… Ø§Ù„Ù…Ø³ØªÙ„Ù…': '',
            'Ø§Ù„Ø­Ø§Ù„Ø©': 'Ø¬Ø¯ÙŠØ¯',
            'Ø§Ù„Ù…ÙˆØ¸Ù Ø§Ù„Ù…Ø¹ÙŠÙ†': '-',
            'Ø¢Ø®Ø± ØªØ­Ø¯ÙŠØ« Ø¨ÙˆØ§Ø³Ø·Ø©': sender_name or '-',
            'Ø¨Ø¯Ø£ Ø§Ù„ØªÙ†ÙÙŠØ° Ø¨ÙˆØ§Ø³Ø·Ø©': '',
            'Ø£ØºÙ„Ù‚ Ø¨ÙˆØ§Ø³Ø·Ø©': '',
            'Ø§Ù„ÙˆÙ‚Øª': '',
            'Ø§Ù„Ù…Ù„Ù': file_name
        }

        df = pd.concat([df, pd.DataFrame([new_row])], ignore_index=True)
        save_requests(df)

        # ğŸ” Ø¥Ø¶Ø§ÙØ© Ù…Ø²Ø§Ù…Ù†Ø© ÙˆÙ†Ø³Ø® Ø§Ø­ØªÙŠØ§Ø·ÙŠ ÙƒØ§Ù…Ù„Ø© Ø¨Ø¹Ø¯ Ø¥Ù†Ø´Ø§Ø¡ Ø·Ù„Ø¨
        try:
            full_sync_and_backup()
        except Exception as _e:
            print("âš ï¸ post-create_request full_sync skipped:", _e)

        return jsonify({"success": True})
    except Exception as e:
        print("âŒ create_request error:", e)
        return jsonify({"success": False, "message": str(e)}), 500

@app.route('/uploads/<path:filename>')
def get_uploaded_file(filename):
    # âœ… ÙŠØ¹Ø±Ø¶ Ø§Ù„Ù…Ù„Ù Ù…Ø¨Ø§Ø´Ø±Ø© Ø¯Ø§Ø®Ù„ Ø§Ù„Ù…ØªØµÙØ­ Ø¨Ø¯Ù„ Ø§Ù„ØªØ­Ù…ÙŠÙ„
    return send_from_directory(UPLOAD_DIR, filename)

@app.route('/api/update_request_status', methods=['POST'])
def update_request_status():
    data = request.get_json()
    req_id = (data.get('requestId','') or '').strip()
    new_status = (data.get('status','') or '').strip()
    updater = (data.get('updater','') or '').strip()
    duration = data.get('duration')

    df = load_requests()
    if df.empty or 'Ø±Ù‚Ù… Ø§Ù„Ø·Ù„Ø¨' not in df.columns:
        return jsonify({"success": False}), 404

    idx_list = df.index[df['Ø±Ù‚Ù… Ø§Ù„Ø·Ù„Ø¨'] == req_id].tolist()
    if not idx_list:
        return jsonify({"success": False}), 404
    idx = idx_list[0]

    # âœ… Ø¶Ù…Ø§Ù† Ø£Ù† Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù†ØµÙŠØ© Ù‡ÙŠ Ù…Ù† Ù†ÙˆØ¹ str Ù„ØªÙØ§Ø¯ÙŠ ØªØ­Ø°ÙŠØ± pandas
    text_cols = ['Ø§Ø³Ù… Ø§Ù„Ù…Ø³ØªÙ„Ù…', 'Ø¨Ø¯Ø£ Ø§Ù„ØªÙ†ÙÙŠØ° Ø¨ÙˆØ§Ø³Ø·Ø©', 'Ø£ØºÙ„Ù‚ Ø¨ÙˆØ§Ø³Ø·Ø©', 'Ø¢Ø®Ø± ØªØ­Ø¯ÙŠØ« Ø¨ÙˆØ§Ø³Ø·Ø©', 'Ø§Ù„ÙˆÙ‚Øª']
    for col in text_cols:
        if col in df.columns:
            df[col] = df[col].astype(str)

    # ğŸ”¹ ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø­Ø§Ù„Ø© ÙˆØ§Ù„Ø§Ø³Ù…
    df.at[idx, 'Ø§Ù„Ø­Ø§Ù„Ø©'] = new_status
    df.at[idx, 'Ø¢Ø®Ø± ØªØ­Ø¯ÙŠØ« Ø¨ÙˆØ§Ø³Ø·Ø©'] = updater

    # ğŸ”¹ ØªØ¹ÙŠÙŠÙ† Ø§Ø³Ù… Ø§Ù„Ù…Ø³ØªÙ„Ù… ÙÙ‚Ø· Ø¥Ø°Ø§ Ù„Ù… ÙŠÙƒÙ† Ù…ÙˆØ¬ÙˆØ¯ Ø³Ø§Ø¨Ù‚Ù‹Ø§
    if not df.at[idx, 'Ø§Ø³Ù… Ø§Ù„Ù…Ø³ØªÙ„Ù…']:
        df.at[idx, 'Ø§Ø³Ù… Ø§Ù„Ù…Ø³ØªÙ„Ù…'] = updater

    if new_status == 'Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªÙ†ÙÙŠØ°':
        df.at[idx, 'Ø¨Ø¯Ø£ Ø§Ù„ØªÙ†ÙÙŠØ° Ø¨ÙˆØ§Ø³Ø·Ø©'] = updater
        df.at[idx, 'ÙˆÙ‚Øª Ø§Ù„Ø¨Ø¯Ø§ÙŠØ©'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')

    elif new_status == 'Ù…Ø¹Ù„Ù‚':
        df.at[idx, 'ÙˆÙ‚Øª Ø§Ù„ØªÙˆÙ‚Ù Ø§Ù„Ù…Ø¤Ù‚Øª'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')

    elif new_status == 'Ù…ØºÙ„Ù‚':
        if 'ÙˆÙ‚Øª Ø§Ù„Ø¨Ø¯Ø§ÙŠØ©' in df.columns:
            start_str = df.at[idx, 'ÙˆÙ‚Øª Ø§Ù„Ø¨Ø¯Ø§ÙŠØ©']
            if start_str:
                start_time = datetime.strptime(start_str, '%Y-%m-%d %H:%M:%S')
                diff = datetime.now() - start_time
                df.at[idx, 'Ø§Ù„ÙˆÙ‚Øª'] = str(diff).split('.')[0]
        if duration:
            df.at[idx, 'Ø§Ù„ÙˆÙ‚Øª'] = duration
        df.at[idx, 'Ø£ØºÙ„Ù‚ Ø¨ÙˆØ§Ø³Ø·Ø©'] = updater

    if new_status == 'Ù…Ø¹Ù„Ù‚':
        # Ø­ÙØ¸ ÙˆÙ‚Øª Ø§Ù„Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„Ù…Ø¤Ù‚Øª ÙÙ‚Ø·
        if 'ÙˆÙ‚Øª Ø§Ù„Ø¨Ø¯Ø§ÙŠØ©' in df.columns:
            start_str = df.at[idx, 'ÙˆÙ‚Øª Ø§Ù„Ø¨Ø¯Ø§ÙŠØ©']
            if start_str:
                start_time = datetime.strptime(start_str, '%Y-%m-%d %H:%M:%S')
                diff = datetime.now() - start_time
                df.at[idx, 'Ø§Ù„ÙˆÙ‚Øª'] = str(diff).split('.')[0]

    save_requests(df)
    # ğŸ” Ø¥Ø¶Ø§ÙØ© Ù…Ø²Ø§Ù…Ù†Ø© ÙˆÙ†Ø³Ø® Ø§Ø­ØªÙŠØ§Ø·ÙŠ Ø¨Ø¹Ø¯ ØªØ­Ø¯ÙŠØ« Ø­Ø§Ù„Ø© Ø§Ù„Ø·Ù„Ø¨
    try:
        full_sync_and_backup()
    except Exception as _e:
        print("âš ï¸ post-update_request_status full_sync skipped:", _e)
    return jsonify({"success": True})


@app.route('/api/delegate_request', methods=['POST'])
def delegate_request():
    data = request.get_json() or {}

    # âœ… ÙŠØ¯Ø¹Ù… ÙƒÙ„ Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ù…ÙØ§ØªÙŠØ­ (camelCase Ø£Ùˆ snake_case)
    req_id = data.get('requestId') or data.get('request_id')
    delegate = data.get('delegate') or data.get('delegateName')
    delegated_by = data.get('delegatedBy') or data.get('delegated_by')

    if not req_id or not delegate:
        return jsonify({'success': False, 'message': 'Ø¨ÙŠØ§Ù†Ø§Øª ØºÙŠØ± Ù…ÙƒØªÙ…Ù„Ø© (Ø±Ù‚Ù… Ø§Ù„Ø·Ù„Ø¨ Ø£Ùˆ Ø§Ø³Ù… Ø§Ù„Ù…ÙˆØ¸Ù Ù…ÙÙ‚ÙˆØ¯)'})

    df = load_requests()
    if df.empty or 'Ø±Ù‚Ù… Ø§Ù„Ø·Ù„Ø¨' not in df.columns:
        return jsonify({'success': False, 'message': 'Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø·Ù„Ø¨Ø§Øª ÙØ§Ø±ØºØ©'})

    mask = df['Ø±Ù‚Ù… Ø§Ù„Ø·Ù„Ø¨'] == req_id
    if not mask.any():
        return jsonify({'success': False, 'message': f'Ø§Ù„Ø·Ù„Ø¨ {req_id} ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯'})

    # âœ… ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø­Ù‚ÙˆÙ„
    df.loc[mask, 'Ø§Ø³Ù… Ø§Ù„Ù…Ø³ØªÙ„Ù…'] = delegate
    df.loc[mask, 'Ø¢Ø®Ø± ØªØ­Ø¯ÙŠØ« Ø¨ÙˆØ§Ø³Ø·Ø©'] = delegated_by
    df.loc[mask, 'Ø§Ù„Ø­Ø§Ù„Ø©'] = 'Ù…ÙˆÙƒÙ„'

    save_requests(df)
    print(f"âœ… ØªÙ… ØªÙˆÙƒÙŠÙ„ Ø§Ù„Ø·Ù„Ø¨ {req_id} Ø¥Ù„Ù‰ {delegate} Ø¨ÙˆØ§Ø³Ø·Ø© {delegated_by}")
    # ğŸ” Ø¥Ø¶Ø§ÙØ© Ù…Ø²Ø§Ù…Ù†Ø© ÙˆÙ†Ø³Ø® Ø§Ø­ØªÙŠØ§Ø·ÙŠ Ø¨Ø¹Ø¯ Ø§Ù„ØªÙˆÙƒÙŠÙ„
    try:
        full_sync_and_backup()
    except Exception as _e:
        print("âš ï¸ post-delegate_request full_sync skipped:", _e)
    return jsonify({'success': True})

# ============== API: ØªØµØ¯ÙŠØ± Ø§Ù„Ø·Ù„Ø¨Ø§Øª ==============
@app.route('/api/export_requests', methods=['POST'])
def export_requests():
    """
    ğŸ“¦ ØªØµØ¯ÙŠØ± Ø§Ù„Ø·Ù„Ø¨Ø§Øª Ø¥Ù„Ù‰ Ù…Ù„Ù Excel ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø¹Ø¯Ø© Ø£ÙˆØ±Ø§Ù‚:
    âœ… ÙÙ‚Ø· Ø§Ù„Ø·Ù„Ø¨Ø§Øª Ø§Ù„ØªÙŠ Ø§Ø³ØªÙ„Ù…Ù‡Ø§ Ø§Ù„Ù‚Ø³Ù… (Ø§Ù„Ù‚Ø³Ù… Ø§Ù„Ù…Ø³ØªÙ„Ù…)
    ÙƒÙ„ ÙˆØ±Ù‚Ø© ØªÙ…Ø«Ù„ Ø­Ø§Ù„Ø© Ù…Ù† Ø­Ø§Ù„Ø§Øª Ø§Ù„Ø·Ù„Ø¨ (Ø¬Ø¯ÙŠØ¯ØŒ Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªÙ†ÙÙŠØ°ØŒ Ù…ØºÙ„Ù‚ØŒ Ù…Ø±ÙÙˆØ¶ØŒ Ø¥Ù„Ø®)
    """
    try:
        data = request.get_json() or {}
        dept = (data.get('department', '') or '').strip()
        start = (data.get('start_date', '') or '').strip()
        end   = (data.get('end_date', '') or '').strip()

        if not os.path.exists(REQUESTS_PATH):
            return jsonify({"success": False, "message": "Ù…Ù„Ù Ø§Ù„Ø·Ù„Ø¨Ø§Øª ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯."})

        df = pd.read_excel(REQUESTS_PATH)
        if df.empty:
            return jsonify({"success": False, "message": "Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª Ù„ØªØµØ¯ÙŠØ±Ù‡Ø§."})

        # ğŸ§¹ ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…Ù‡Ù…Ø©
        for col in ['Ø§Ù„Ù‚Ø³Ù… Ø§Ù„Ù…Ø³ØªÙ„Ù…', 'Ø§Ù„Ø­Ø§Ù„Ø©', 'Ø§Ù„ØªØ§Ø±ÙŠØ®']:
            if col in df.columns:
                df[col] = (
                    df[col]
                    .astype(str)
                    .str.strip()
                    .str.replace('\u200f', '', regex=True)
                    .str.replace('\u200e', '', regex=True)
                )

        # âœ… ÙÙ„ØªØ±Ø© Ø§Ù„Ø·Ù„Ø¨Ø§Øª Ø§Ù„ØªÙŠ Ø§Ø³ØªÙ„Ù…Ù‡Ø§ Ø§Ù„Ù‚Ø³Ù… ÙÙ‚Ø·
        dept_norm = normalize_arabic(dept)
        df = df[df['Ø§Ù„Ù‚Ø³Ù… Ø§Ù„Ù…Ø³ØªÙ„Ù…'].apply(lambda x: dept_norm in normalize_arabic(x) or normalize_arabic(x) in dept_norm)]

        # âœ… ÙÙ„ØªØ±Ø© Ø­Ø³Ø¨ Ø§Ù„ØªØ§Ø±ÙŠØ® Ø¥Ù† ÙˆØ¬Ø¯
        if start:
            df = df[pd.to_datetime(df['Ø§Ù„ØªØ§Ø±ÙŠØ®'], errors='coerce') >= pd.to_datetime(start)]
        if end:
            end_dt = pd.to_datetime(end) + pd.Timedelta(days=1) - pd.Timedelta(seconds=1)
            df = df[pd.to_datetime(df['Ø§Ù„ØªØ§Ø±ÙŠØ®'], errors='coerce') <= end_dt]

        if df.empty:
            return jsonify({"success": False, "message": "Ù„Ø§ ØªÙˆØ¬Ø¯ Ø·Ù„Ø¨Ø§Øª Ø§Ø³ØªÙ„Ù…Ù‡Ø§ Ø§Ù„Ù‚Ø³Ù… Ø¶Ù…Ù† Ø§Ù„Ø´Ø±ÙˆØ· Ø§Ù„Ù…Ø­Ø¯Ø¯Ø©."})

        # ğŸ—‚ï¸ ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø­Ø³Ø¨ Ø§Ù„Ø­Ø§Ù„Ø©
        grouped = {status: sub_df for status, sub_df in df.groupby('Ø§Ù„Ø­Ø§Ù„Ø©')}

        # ğŸ“˜ Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„Ù Excel Ø¨Ø¹Ø¯Ø© Ø£ÙˆØ±Ø§Ù‚ (ÙƒÙ„ ÙˆØ±Ù‚Ø© = Ø­Ø§Ù„Ø©)
        ts = datetime.now().strftime('%Y%m%d_%H%M%S')
        fname = f"Ø·Ù„Ø¨Ø§Øª_Ø§Ù„ÙˆØ§Ø±Ø¯Ø©_{dept}_{ts}.xlsx".replace(' ', '_')
        fpath = os.path.join(EXPORT_DIR, fname)

        with pd.ExcelWriter(fpath, engine='openpyxl') as writer:
            for status, sub_df in grouped.items():
                clean_status = str(status).replace('/', '-').strip() or 'ØºÙŠØ±_Ù…Ø­Ø¯Ø¯'
                sub_df.to_excel(writer, index=False, sheet_name=clean_status[:31])

        return jsonify({"success": True, "file": fname})

    except Exception as e:
        print("âŒ export_requests error:", e)
        return jsonify({"success": False, "message": f"Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„ØªØµØ¯ÙŠØ±: {str(e)}"})

@app.route('/download/<path:filename>')
def download(filename):
    return send_from_directory(EXPORT_DIR, filename, as_attachment=True)

# ============== API: Ø§Ù„Ø´Ø§Øª Ø§Ù„Ø¹Ø§Ù… ==============
@app.route("/chatbot", methods=["POST"])
def chatbot():
    """Ø±Ø¯ Ø°ÙƒÙŠ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… OpenRouter Ø¨Ø³Ø±Ø¹Ø© Ø£Ø¹Ù„Ù‰"""
    user_input = request.json.get("message", "").strip()
    if not user_input:
        return jsonify({"reply": "Ø§Ù„Ø±Ø³Ø§Ù„Ø© ÙØ§Ø±ØºØ©!"})

    headers = {
        "Authorization": f"Bearer {OPENROUTER_API_KEY}",
        "Content-Type": "application/json",
    }

    payload = {
        "model": "qwen/qwen-2.5-7b-instruct",
        "messages": [
            {"role": "system", "content": "Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ Ø°ÙƒÙŠ ØªØªØ­Ø¯Ø« Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© ÙˆØªØ³Ø§Ø¹Ø¯ Ù…ÙˆØ¸ÙÙŠ Ù†Ø¸Ø§Ù… SEVENS."},
            {"role": "user", "content": user_input}
        ],
        "temperature": 0.6,
        "max_tokens": 200
    }

    try:
        response = requests.post(
            "https://openrouter.ai/api/v1/chat/completions",
            headers=headers,
            json=payload,
            timeout=15,   # â±ï¸ Ø£Ù‚ØµÙ‰ Ù…Ù‡Ù„Ø© Ù„Ù„Ø±Ø¯ 15 Ø«Ø§Ù†ÙŠØ© ÙÙ‚Ø·
        )

        if response.status_code == 200:
            data = response.json()
            if "choices" in data and len(data["choices"]) > 0:
                reply = data["choices"][0]["message"]["content"].strip()
                return jsonify({"reply": reply})
            else:
                return jsonify({"reply": "Ù„Ù… ÙŠØµÙ„ Ø±Ø¯ Ù…Ù† Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ."})
        else:
            print("âŒ OpenRouter Error:", response.text)
            return jsonify({"reply": "Ø­Ø¯Ø« Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø®Ø§Ø¯Ù… Ø£Ø«Ù†Ø§Ø¡ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø·Ù„Ø¨."})

    except requests.Timeout:
        return jsonify({"reply": "Ø§Ù„Ø®Ø§Ø¯Ù… ØªØ£Ø®Ø± ÙÙŠ Ø§Ù„Ø±Ø¯ØŒ Ø­Ø§ÙˆÙ„ Ù…Ø±Ø© Ø£Ø®Ø±Ù‰ Ù„Ø§Ø­Ù‚Ø§Ù‹."})
    except Exception as e:
        print("âŒ chatbot error:", e)
        return jsonify({"reply": "ØªØ¹Ø°Ø± Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ø®Ø¯Ù…Ø© Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ."})

# ============== API: Ø¯Ø±Ø¯Ø´Ø© Ø¨ÙŠÙ† Ø§Ù„Ù…ÙˆØ¸ÙÙŠÙ† ==============
CHAT_UPLOAD_DIR = os.path.join(BASE_DIR, "chat_uploads")
os.makedirs(CHAT_UPLOAD_DIR, exist_ok=True)

@app.route('/api/chat_send_file', methods=['POST'])
def chat_send_file():
    req_id = request.form.get('request_id')
    sender = request.form.get('sender')
    dept = request.form.get('department')
    msg = request.form.get('message', '')
    file = request.files.get('file')
    filename = ""

    if file:
        safe_name = f"{req_id}_{datetime.now().strftime('%Y%m%d_%H%M%S')}_{file.filename}"
        path = os.path.join(CHAT_UPLOAD_DIR, safe_name)
        file.save(path)
        filename = safe_name

    df = load_chats()
    new = pd.DataFrame([{
        'Ø±Ù‚Ù… Ø§Ù„Ø·Ù„Ø¨': req_id,
        'Ø§Ù„Ù…Ø±Ø³Ù„': sender,
        'Ø§Ù„Ù‚Ø³Ù…': dept,
        'Ø§Ù„Ø±Ø³Ø§Ù„Ø©': msg,
        'Ø§Ù„Ù…Ù„Ù': filename,
        'Ø§Ù„ÙˆÙ‚Øª': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    }])
    df = pd.concat([df, new], ignore_index=True)
    df.to_excel(CHAT_PATH, index=False)

    # âœ… ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø·Ù„Ø¨ Ø¨Ø¢Ø®Ø± Ù…Ø±Ø³Ù„
    req_df = load_requests()
    mask = req_df['Ø±Ù‚Ù… Ø§Ù„Ø·Ù„Ø¨'] == req_id
    if mask.any():
        req_df.loc[mask, 'Ø¢Ø®Ø± ØªØ­Ø¯ÙŠØ« Ø¨ÙˆØ§Ø³Ø·Ø©'] = sender
        save_requests(req_df)

        # ğŸ” Ø¥Ø¶Ø§ÙØ© Ù…Ø²Ø§Ù…Ù†Ø© ÙˆÙ†Ø³Ø® Ø§Ø­ØªÙŠØ§Ø·ÙŠ Ø¨Ø¹Ø¯ Ø¥Ø±Ø³Ø§Ù„ Ù…Ù„Ù Ø¯Ø±Ø¯Ø´Ø©
    try:
        full_sync_and_backup()
    except Exception as _e:
        print("âš ï¸ post-chat_send_file full_sync skipped:", _e)

    return jsonify({"success": True})

@app.route('/api/chat_get/<req_id>', methods=['GET'])
def chat_get(req_id):
    """Ø¥Ø±Ø¬Ø§Ø¹ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø±Ø³Ø§Ø¦Ù„ Ø§Ù„Ø®Ø§ØµØ© Ø¨Ø·Ù„Ø¨ Ù…Ø­Ø¯Ø¯"""
    try:
        df = load_chats()
        if df.empty:
            return jsonify([])
        msgs = df[df['Ø±Ù‚Ù… Ø§Ù„Ø·Ù„Ø¨'].astype(str) == str(req_id)].fillna('').to_dict(orient='records')
        return jsonify(msgs)
    except Exception as e:
        print("âŒ chat_get error:", e)
        return jsonify([])


@app.route('/chat_uploads/<path:filename>')
def chat_uploads(filename):
    return send_from_directory(CHAT_UPLOAD_DIR, filename)

@app.route('/api/force_reset_password', methods=['POST'])
def force_reset_password():
    data = request.get_json() or {}

    email = (data.get("email") or "").strip().lower()
    new_password = (data.get("newPassword") or "").strip()

    if not email or not new_password:
        return jsonify({"success": False, "message": "Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù†Ø§Ù‚ØµØ©"}), 400

    df = pd.read_excel(DB_PATH)

    # Ø§ÙƒØªØ´Ø§Ù Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ø¨Ø±ÙŠØ¯ ÙˆÙƒÙ„Ù…Ø© Ø§Ù„Ù…Ø±ÙˆØ±
    email_col = next((c for c in df.columns if "Ø¨Ø±ÙŠØ¯" in c or "email" in c.lower()), None)
    pass_col  = next((c for c in df.columns if "Ù…Ø±ÙˆØ±" in c or "pass" in c.lower()), None)

    if "force_reset" not in df.columns:
        df["force_reset"] = "1"

    df[email_col] = df[email_col].astype(str).str.lower().str.strip()
    mask = df[email_col] == email

    if not mask.any():
        return jsonify({"success": False, "message": "Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯"}), 404

    # ØªØ­Ø¯ÙŠØ« ÙƒÙ„Ù…Ø© Ø§Ù„Ù…Ø±ÙˆØ±
    df.loc[mask, pass_col] = new_password

    # ØªØµØ­ÙŠØ­ force_reset
    df["force_reset"] = df["force_reset"].astype(str)
    df["force_reset"] = df["force_reset"].str.replace(".0", "", regex=False).str.replace(".00", "", regex=False).str.strip()

    df.loc[mask, "force_reset"] = "0"

    # â­â­ Ø§Ù„Ø­ÙØ¸ Ø§Ù„ÙØ¹Ù„ÙŠ ÙÙŠ Excel
    df.to_excel(DB_PATH, index=False)

    # ØªØ³Ø¬ÙŠÙ„ Ø®Ø±ÙˆØ¬ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
    session.pop("user", None)

    return jsonify({"success": True, "message": "ØªÙ… ØªØ­Ø¯ÙŠØ« ÙƒÙ„Ù…Ø© Ø§Ù„Ù…Ø±ÙˆØ±"})


# ============== API: Ø§Ø³ØªØ¹Ø§Ø¯Ø© / Ø¥Ø¹Ø§Ø¯Ø© ØªØ¹ÙŠÙŠÙ† ÙƒÙ„Ù…Ø© Ø§Ù„Ù…Ø±ÙˆØ± ==============
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart
import random
from flask import session
from google.oauth2.credentials import Credentials
from google_auth_oauthlib.flow import InstalledAppFlow
from google.auth.transport.requests import Request
import base64


GMAIL_SCOPES = ["https://www.googleapis.com/auth/gmail.send"]


GMAIL_CREDENTIALS_PATH = os.path.join(DATA_DIR, "gmail_credentials.json")
GMAIL_TOKEN_PATH = os.path.join(DATA_DIR, "gmail_token.json")

def get_gmail_service():

    creds = None


    if os.path.exists(GMAIL_TOKEN_PATH):
        creds = Credentials.from_authorized_user_file(GMAIL_TOKEN_PATH, GMAIL_SCOPES)


    if not creds or not creds.valid:
        if creds and creds.expired and creds.refresh_token:
            creds.refresh(Request())
        else:

            flow = InstalledAppFlow.from_client_secrets_file(
                GMAIL_CREDENTIALS_PATH,
                GMAIL_SCOPES
            )
            creds = flow.run_local_server(port=0)


        with open(GMAIL_TOKEN_PATH, "w", encoding="utf-8") as token:
            token.write(creds.to_json())

    from googleapiclient.discovery import build
    service = build("gmail", "v1", credentials=creds)
    return service

def send_html_email_via_gmail(to_email: str, subject: str, html_body: str):

    try:
        service = get_gmail_service()

        msg = MIMEMultipart("alternative")
        msg["To"] = to_email
        msg["From"] = "SEVENS System"
        msg["Subject"] = subject

        msg.attach(MIMEText(html_body, "html", "utf-8"))

        raw = base64.urlsafe_b64encode(msg.as_bytes()).decode("utf-8")
        body = {"raw": raw}

        service.users().messages().send(userId="me", body=body).execute()
        print(f"âœ… Gmail API: email sent to {to_email}")

    except Exception as e:
        print("âŒ Gmail API send error:", e)

# ================================
# API: Ø¥Ø±Ø³Ø§Ù„ Ø±Ù…Ø² Ø§Ù„ØªØ­Ù‚Ù‚ Ø¹Ø¨Ø± SMTP
# ================================
@app.route('/api/send_reset_code', methods=['POST'])
def send_reset_code():
    import threading, time

    data = request.get_json() or {}
    email = (data.get("email") or "").strip().lower()

    if not email:
        return jsonify({"success": False, "message": "ÙŠØ±Ø¬Ù‰ Ø¥Ø¯Ø®Ø§Ù„ Ø§Ù„Ø¨Ø±ÙŠØ¯"}), 400

    # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø§Ù„Ø¨Ø±ÙŠØ¯ ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
    if not os.path.exists(DB_PATH):
        return jsonify({"success": False, "message": "Ù…Ù„Ù Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ† ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯"}), 500

    df = pd.read_excel(DB_PATH)
    df_cols = [str(c).replace(" ", "").lower() for c in df.columns]

    email_variants = ["Ø§Ù„Ø¨Ø±ÙŠØ¯Ø§Ù„Ø§Ù„ÙƒØªØ±ÙˆÙ†ÙŠ", "Ø§Ù„Ø¨Ø±ÙŠØ¯Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠ", "Ø§Ù„Ø§ÙŠÙ…ÙŠÙ„", "email"]
    email_col = None

    for i, col in enumerate(df_cols):
        if any(v in col for v in email_variants):
            email_col = df.columns[i]
            break

    if not email_col:
        return jsonify({"success": False, "message": "Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ø¹Ù…ÙˆØ¯ Ø¨Ø±ÙŠØ¯ Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠ"}), 500

    df[email_col] = df[email_col].astype(str).str.lower().str.strip()

    if email not in df[email_col].values:
        return jsonify({"success": False, "message": "Ø§Ù„Ø¨Ø±ÙŠØ¯ ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯"}), 404

    # Ø¥Ù†Ø´Ø§Ø¡ Ø±Ù…Ø² Ø§Ù„ØªØ­Ù‚Ù‚
    code = str(random.randint(100000, 999999))

    session["reset_code"] = code
    session["reset_email"] = email
    session["reset_code_time"] = time.time()
    session["reset_verified"] = False

    # Ø§Ù„Ø±Ø³Ø§Ù„Ø© HTML
    subject = "Ø±Ù…Ø² Ø§Ù„ØªØ­Ù‚Ù‚ Ù„Ø¥Ø¹Ø§Ø¯Ø© ØªØ¹ÙŠÙŠÙ† ÙƒÙ„Ù…Ø© Ø§Ù„Ù…Ø±ÙˆØ± - SEVENS"
    html = f"""
    <html><body style='direction:rtl;font-family:Tajawal;'>
        <h3>Ø±Ù…Ø² Ø§Ù„ØªØ­Ù‚Ù‚ Ø§Ù„Ø®Ø§Øµ Ø¨Ùƒ</h3>
        <p>Ø±Ù…Ø²Ùƒ Ù‡Ùˆ:</p>
        <div style='font-size:32px;font-weight:bold;color:#1976d2'>{code}</div>
        <p>ØµØ§Ù„Ø­ Ù„Ù…Ø¯Ø© 10 Ø¯Ù‚Ø§Ø¦Ù‚.</p>
    </body></html>
    """

    def send_email_background():
        try:
            send_html_email_via_company(email, subject, html)
        except Exception as e:
            print("âŒ SMTP background error:", e)

    threading.Thread(target=send_email_background, daemon=True).start()

    return jsonify({"success": True, "message": "ØªÙ… Ø¥Ø±Ø³Ø§Ù„ Ø±Ù…Ø² Ø§Ù„ØªØ­Ù‚Ù‚"})


# ============== API: Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø±Ù…Ø² Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„ØªØ¹ÙŠÙŠÙ† ==============
@app.route('/api/verify_reset_code', methods=['POST'])
def verify_reset_code():
    import time

    data = request.get_json() or {}
    code = (data.get("code") or "").strip()

    saved_code = session.get("reset_code")
    saved_time = session.get("reset_code_time")

    if not saved_code or not saved_time:
        return jsonify({"success": False, "message": "Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ø±Ù…Ø² Ù…ÙØ±Ø³Ù„"}), 400

    if time.time() - float(saved_time) > 600:
        session.pop("reset_code", None)
        session.pop("reset_email", None)
        session.pop("reset_code_time", None)
        return jsonify({"success": False, "message": "Ø§Ù†ØªÙ‡Øª ØµÙ„Ø§Ø­ÙŠØ© Ø§Ù„Ø±Ù…Ø²"}), 400

    if code != saved_code:
        return jsonify({"success": False, "message": "Ø±Ù…Ø² ØºÙŠØ± ØµØ­ÙŠØ­"}), 400

    session["reset_verified"] = True
    return jsonify({"success": True, "message": "ØªÙ… Ø§Ù„ØªØ­Ù‚Ù‚ Ø¨Ù†Ø¬Ø§Ø­"})


@app.route('/api/forgot_reset_password', methods=['POST'])
def forgot_reset_password():
    """ØªØ­Ø¯ÙŠØ« ÙƒÙ„Ù…Ø© Ø§Ù„Ù…Ø±ÙˆØ± Ø¹Ø¨Ø± Ø§Ù„Ø¨Ø±ÙŠØ¯ Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠ Ø¨Ø¯ÙˆÙ† Ø¥Ù†Ø´Ø§Ø¡ Ø¹Ù…ÙˆØ¯ Ø¬Ø¯ÙŠØ¯"""
    try:
        data = request.get_json() or {}
        email = (data.get('email', '') or '').strip().lower()
        new_password = (data.get('newPassword', '') or '').strip()
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø£Ù† Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„ÙƒÙˆØ¯
        if email != session.get("reset_email"):
            return jsonify({"success": False, "message": "ÙŠØ±Ø¬Ù‰ Ø¥Ø¹Ø§Ø¯Ø© Ø·Ù„Ø¨ Ø±Ù…Ø² Ø§Ù„ØªØ­Ù‚Ù‚"}), 403

        if not email or not new_password:
            return jsonify({"success": False, "message": "ÙŠØ±Ø¬Ù‰ Ø¥Ø¯Ø®Ø§Ù„ Ø§Ù„Ø¨Ø±ÙŠØ¯ ÙˆÙƒÙ„Ù…Ø© Ø§Ù„Ù…Ø±ÙˆØ± Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©"}), 400

        df = pd.read_excel(DB_PATH)

        # ğŸ”¹ ØªÙ†Ø¸ÙŠÙ Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ù…Ù† Ø§Ù„Ø±Ù…ÙˆØ² ÙˆØ§Ù„Ù…Ø³Ø§ÙØ§Øª ÙˆØ§Ù„Ø§Ø®ØªÙ„Ø§ÙØ§Øª Ø§Ù„Ø¥Ù…Ù„Ø§Ø¦ÙŠØ©
        df.columns = (
            df.columns.astype(str)
            .str.replace('\u200f', '', regex=True)
            .str.replace('\u200e', '', regex=True)
            .str.replace(' ', '', regex=True)
            .str.strip()
        )

        # ğŸ§© ØªØ¹Ø±ÙŠÙ Ø¬Ù…ÙŠØ¹ Ø§Ø­ØªÙ…Ø§Ù„Ø§Øª Ø§Ø³Ù… Ø§Ù„Ø¹Ù…ÙˆØ¯
        password_variants = ['ÙƒÙ„Ù…Ù‡Ø§Ù„Ù…Ø±ÙˆØ±', 'ÙƒÙ„Ù…Ù‡ Ø§Ù„Ù…Ø±ÙˆØ±', 'ÙƒÙ„Ù…Ø©Ø§Ù„Ù…Ø±ÙˆØ±', 'ÙƒÙ„Ù…Ø© Ø§Ù„Ù…Ø±ÙˆØ±', 'ÙƒÙ„Ù…Ø©Ø§Ù„Ø³Ø±', 'password', 'pass']
        email_variants = ['Ø§Ù„Ø¨Ø±ÙŠØ¯Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠ', 'Ø§Ù„Ø¨Ø±ÙŠØ¯Ø§Ù„Ø§Ù„ÙƒØªØ±ÙˆÙ†ÙŠ', 'Ø§Ù„Ø§ÙŠÙ…ÙŠÙ„', 'email']

        # ğŸ” ØªØ­Ø¯ÙŠØ¯ Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„ÙØ¹Ù„ÙŠØ©
        pass_col = next((col for col in df.columns if any(p.replace(' ', '') in col for p in password_variants)), None)
        email_col = next((col for col in df.columns if any(e.replace(' ', '') in col for e in email_variants)), None)

        if not email_col or not pass_col:
            return jsonify({"success": False, "message": "ØªØ¹Ø°Ø± Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ø¨Ø±ÙŠØ¯ Ø£Ùˆ ÙƒÙ„Ù…Ø© Ø§Ù„Ù…Ø±ÙˆØ± ÙÙŠ Ø§Ù„Ù…Ù„Ù"}), 500

        # ğŸ”¹ ØªÙˆØ­ÙŠØ¯ Ø§Ù„Ø¨Ø±ÙŠØ¯ Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠ Ù„Ù„Ù…Ù‚Ø§Ø±Ù†Ø©
        df[email_col] = df[email_col].astype(str).str.lower().str.strip()

        # ğŸ” Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø§Ù„Ù…Ø³ØªÙ‡Ø¯Ù
        mask = df[email_col] == email
        if not mask.any():
            return jsonify({"success": False, "message": "Ø§Ù„Ø¨Ø±ÙŠØ¯ Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠ ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯"}), 404

        # âœï¸ ØªØ¹Ø¯ÙŠÙ„ ÙƒÙ„Ù…Ø© Ø§Ù„Ù…Ø±ÙˆØ± Ø¯Ø§Ø®Ù„ Ù†ÙØ³ Ø§Ù„Ø¹Ù…ÙˆØ¯ Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯
        df.loc[mask, pass_col] = new_password

        # ğŸ§¼ Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…ÙƒØ±Ø±Ø© Ø§Ù„ØªÙŠ ØªØ­Ù…Ù„ Ù†ÙØ³ Ø§Ù„Ø§Ø³Ù… Ø¨Ø¹Ø¯ Ø§Ù„ØªØ¹Ø¯ÙŠÙ„ (Ù„ØªÙØ§Ø¯ÙŠ Ø§Ù„ØªÙƒØ±Ø§Ø±)
        df = df.loc[:, ~df.columns.duplicated()]

        df.to_excel(DB_PATH, index=False)

        print(f"ğŸ”‘ Password updated successfully for {email} (column: {pass_col})")

        # ğŸ” Ù…Ø²Ø§Ù…Ù†Ø© ØªÙ„Ù‚Ø§Ø¦ÙŠØ© Ø¨Ø¹Ø¯ Ø§Ù„ØªØ¹Ø¯ÙŠÙ„
        try:
            full_sync_and_backup()
        except Exception as _e:
            print("âš ï¸ post-forgot_reset_password full_sync skipped:", _e)

        return jsonify({"success": True, "message": "ØªÙ… ØªØ­Ø¯ÙŠØ« ÙƒÙ„Ù…Ø© Ø§Ù„Ù…Ø±ÙˆØ± Ø¨Ù†Ø¬Ø§Ø­ âœ…"})

    except Exception as e:
        print("âŒ forgot_reset_password error:", e)
        return jsonify({"success": False, "message": "Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ ØªØ­Ø¯ÙŠØ« ÙƒÙ„Ù…Ø© Ø§Ù„Ù…Ø±ÙˆØ±"})

# ====== â˜…â˜…â˜… HR APIs â˜…â˜…â˜… ======

@app.route('/api/hr/list_users', methods=['GET'])
def hr_list_users():
    """Ø¹Ø±Ø¶ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ† ÙƒÙ…Ø§ Ù‡Ù… ÙÙŠ Ù…Ù„Ù Excel Ø¨Ø¯ÙˆÙ† Ø¥Ù†Ø´Ø§Ø¡ Ø£Ø¹Ù…Ø¯Ø© Ø¬Ø¯ÙŠØ¯Ø©"""
    try:
        if not os.path.exists(DB_PATH):
            return jsonify([])

        df = pd.read_excel(DB_PATH)
        df = df.loc[:, ~df.columns.duplicated()]  # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…ÙƒØ±Ø±Ø©
        # âœ… ØªÙˆØ­ÙŠØ¯ Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© (Ø­ØªÙ‰ Ù„Ùˆ Ø§Ø®ØªÙ„ÙØª Ø§Ù„Ù…Ø³Ø§ÙØ§Øª Ø£Ùˆ Ø§Ù„Ù‡Ù…Ø²Ø§Øª)
        rename_map = {
            'ÙƒÙ„Ù…Ù‡Ø§Ù„Ù…Ø±ÙˆØ±': 'ÙƒÙ„Ù…Ø© Ø§Ù„Ù…Ø±ÙˆØ±',
            'ÙƒÙ„Ù…Ù‡ Ø§Ù„Ù…Ø±ÙˆØ±': 'ÙƒÙ„Ù…Ø© Ø§Ù„Ù…Ø±ÙˆØ±',
            'ÙƒÙ„Ù…Ø©Ø§Ù„Ù…Ø±ÙˆØ±': 'ÙƒÙ„Ù…Ø© Ø§Ù„Ù…Ø±ÙˆØ±',
            'ÙƒÙ„Ù…Ø© Ø§Ù„Ø³Ø±': 'ÙƒÙ„Ù…Ø© Ø§Ù„Ù…Ø±ÙˆØ±',
            'password': 'ÙƒÙ„Ù…Ø© Ø§Ù„Ù…Ø±ÙˆØ±',
            'pass': 'ÙƒÙ„Ù…Ø© Ø§Ù„Ù…Ø±ÙˆØ±',
            'Ø§Ù„Ø§ÙŠÙ…ÙŠÙ„': 'Ø§Ù„Ø¨Ø±ÙŠØ¯ Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠ',
            'email': 'Ø§Ù„Ø¨Ø±ÙŠØ¯ Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠ',
            'Ø§Ù„Ø¨Ø±ÙŠØ¯Ø§Ù„Ø§Ù„ÙƒØªØ±ÙˆÙ†ÙŠ': 'Ø§Ù„Ø¨Ø±ÙŠØ¯ Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠ',
            'Ø§Ù„Ø¨Ø±ÙŠØ¯Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠ': 'Ø§Ù„Ø¨Ø±ÙŠØ¯ Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠ',
            'Ø§Ù„Ø­Ø§Ù„Ù‡': 'Ø§Ù„Ø­Ø§Ù„Ø©',
            'status': 'Ø§Ù„Ø­Ø§Ù„Ø©',
            'role': 'Ø§Ù„ØµÙ„Ø§Ø­ÙŠØ©'
        }
        for old, new in rename_map.items():
            if old in df.columns:
                df.rename(columns={old: new}, inplace=True)

        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© ÙÙ‚Ø· (Ø¨Ø¯ÙˆÙ† Ø¥Ù†Ø´Ø§Ø¦Ù‡Ø§)
        required = ['Ø§Ù„Ø§Ø³Ù…','Ø§Ù„ØµÙ„Ø§Ø­ÙŠØ©','ÙƒÙ„Ù…Ø© Ø§Ù„Ù…Ø±ÙˆØ±','Ø§Ù„Ø¨Ø±ÙŠØ¯ Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠ','Ø§Ù„Ù‚Ø³Ù…','Ø§Ù„Ø­Ø§Ù„Ø©']
        for col in required:
            if col not in df.columns:
                print(f"âš ï¸ Ø§Ù„Ù…Ù„Ù Ù†Ø§Ù‚Øµ Ø§Ù„Ø¹Ù…ÙˆØ¯: {col}")
                return jsonify([])

        return jsonify(df.fillna('').to_dict(orient='records'))
    except Exception as e:
        print("hr_list_users error:", e)
        return jsonify([]), 500


@app.route('/api/hr/add_user', methods=['POST'])
def hr_add_user():
    """Ø¥Ø¶Ø§ÙØ© Ù…Ø³ØªØ®Ø¯Ù… Ø¬Ø¯ÙŠØ¯ ÙÙ‚Ø· Ø¨Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø© ÙØ¹Ù„ÙŠÙ‹Ø§"""

    data = request.get_json() or {}
    name  = (data.get('name','') or '').strip()
    role  = (data.get('role','') or '').strip()
    pwd   = (data.get('password','') or '').strip()
    email = (data.get('email','') or '').strip().lower()
    dept  = (data.get('department','') or '').strip()
    status= (data.get('status','Ù†Ø´Ø·') or 'Ù†Ø´Ø·').strip()
    extra = (data.get("extra_departments", "") or "").strip()

    if not all([name, role, pwd, email, dept]):
        return jsonify({"success": False, "message": "Ø§Ù„Ø­Ù‚ÙˆÙ„ Ù…Ø·Ù„ÙˆØ¨Ø©"}), 400

    if not os.path.exists(DB_PATH):
        return jsonify({"success": False, "message": "Ù…Ù„Ù Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ† ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯"}), 500

    df = pd.read_excel(DB_PATH)
    df = df.loc[:, ~df.columns.duplicated()]
    # âœ… ØªÙˆØ­ÙŠØ¯ Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© (Ø­ØªÙ‰ Ù„Ùˆ Ø§Ø®ØªÙ„ÙØª Ø§Ù„Ù…Ø³Ø§ÙØ§Øª Ø£Ùˆ Ø§Ù„Ù‡Ù…Ø²Ø§Øª)
    rename_map = {
        'ÙƒÙ„Ù…Ù‡Ø§Ù„Ù…Ø±ÙˆØ±': 'ÙƒÙ„Ù…Ø© Ø§Ù„Ù…Ø±ÙˆØ±',
        'ÙƒÙ„Ù…Ù‡ Ø§Ù„Ù…Ø±ÙˆØ±': 'ÙƒÙ„Ù…Ø© Ø§Ù„Ù…Ø±ÙˆØ±',
        'ÙƒÙ„Ù…Ø©Ø§Ù„Ù…Ø±ÙˆØ±': 'ÙƒÙ„Ù…Ø© Ø§Ù„Ù…Ø±ÙˆØ±',
        'ÙƒÙ„Ù…Ø© Ø§Ù„Ø³Ø±': 'ÙƒÙ„Ù…Ø© Ø§Ù„Ù…Ø±ÙˆØ±',
        'password': 'ÙƒÙ„Ù…Ø© Ø§Ù„Ù…Ø±ÙˆØ±',
        'pass': 'ÙƒÙ„Ù…Ø© Ø§Ù„Ù…Ø±ÙˆØ±',
        'Ø§Ù„Ø§ÙŠÙ…ÙŠÙ„': 'Ø§Ù„Ø¨Ø±ÙŠØ¯ Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠ',
        'email': 'Ø§Ù„Ø¨Ø±ÙŠØ¯ Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠ',
        'Ø§Ù„Ø¨Ø±ÙŠØ¯Ø§Ù„Ø§Ù„ÙƒØªØ±ÙˆÙ†ÙŠ': 'Ø§Ù„Ø¨Ø±ÙŠØ¯ Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠ',
        'Ø§Ù„Ø¨Ø±ÙŠØ¯Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠ': 'Ø§Ù„Ø¨Ø±ÙŠØ¯ Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠ',
        'Ø§Ù„Ø­Ø§Ù„Ù‡': 'Ø§Ù„Ø­Ø§Ù„Ø©',
        'status': 'Ø§Ù„Ø­Ø§Ù„Ø©',
        'role': 'Ø§Ù„ØµÙ„Ø§Ø­ÙŠØ©'
    }
    for old, new in rename_map.items():
        if old in df.columns:
            df.rename(columns={old: new}, inplace=True)

    required_cols = ['Ø§Ù„Ø§Ø³Ù…','Ø§Ù„ØµÙ„Ø§Ø­ÙŠØ©','ÙƒÙ„Ù…Ø© Ø§Ù„Ù…Ø±ÙˆØ±','Ø§Ù„Ø¨Ø±ÙŠØ¯ Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠ','Ø§Ù„Ù‚Ø³Ù…','Ø§Ù„Ø­Ø§Ù„Ø©']
    for col in required_cols:
        if col not in df.columns:
            return jsonify({"success": False, "message": f"Ø§Ù„Ù…Ù„Ù Ù†Ø§Ù‚Øµ Ø§Ù„Ø¹Ù…ÙˆØ¯: {col}"}), 500

    # Ù…Ù†Ø¹ Ø§Ù„ØªÙƒØ±Ø§Ø± Ø¨Ø§Ù„Ø¨Ø±ÙŠØ¯
    mask = df['Ø§Ù„Ø¨Ø±ÙŠØ¯ Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠ'].astype(str).str.lower().str.strip() == email
    if mask.any():
        return jsonify({"success": False, "message": "Ø§Ù„Ø¨Ø±ÙŠØ¯ Ù…ÙˆØ¬ÙˆØ¯ Ù…Ø³Ø¨Ù‚Ø§Ù‹"}), 409

    new_row = {
        'Ø§Ù„Ø§Ø³Ù…': name,
        'Ø§Ù„ØµÙ„Ø§Ø­ÙŠØ©': role,
        'ÙƒÙ„Ù…Ø© Ø§Ù„Ù…Ø±ÙˆØ±': pwd,
        'Ø§Ù„Ø¨Ø±ÙŠØ¯ Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠ': email,
        'Ø§Ù„Ù‚Ø³Ù…': dept,
        'Ø§Ù„Ø­Ø§Ù„Ø©': status,
        'Ø§Ù„Ø£Ù‚Ø³Ø§Ù… Ø§Ù„Ø£Ø®Ø±Ù‰': extra

    }

    # Ø§Ù„Ø§Ø­ØªÙØ§Ø¸ ÙÙ‚Ø· Ø¨Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø©
    df = pd.concat([df, pd.DataFrame([[new_row.get(c, '') for c in df.columns]], columns=df.columns)], ignore_index=True)
    df.to_excel(DB_PATH, index=False)
    print(f"âœ… ØªÙ…Øª Ø¥Ø¶Ø§ÙØ© Ù…Ø³ØªØ®Ø¯Ù… Ø¬Ø¯ÙŠØ¯: {email}")

    return jsonify({"success": True})


@app.route('/api/hr/update_user', methods=['POST'])
def hr_update_user():
    """ØªØ­Ø¯ÙŠØ« Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… + ØªØ­Ø¯ÙŠØ« Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø·Ù„Ø¨Ø§Øª Ø§Ù„Ù…Ø±ØªØ¨Ø·Ø© + Ù…Ø²Ø§Ù…Ù†Ø© ÙƒØ§Ù…Ù„Ø©"""

    data = request.get_json() or {}

    email = (data.get('email','') or '').strip().lower()
    if not email:
        return jsonify({"success": False, "message": "Ø§Ù„Ø¨Ø±ÙŠØ¯ Ù…Ø·Ù„ÙˆØ¨"}), 400

    # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ† Ù…Ù† Excel
    df = pd.read_excel(DB_PATH)
    df = df.loc[:, ~df.columns.duplicated()]

    # ØªÙˆØ­ÙŠØ¯ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©
    rename_map = {
        'Ø§Ù„Ø§ÙŠÙ…ÙŠÙ„': 'Ø§Ù„Ø¨Ø±ÙŠØ¯ Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠ',
        'email': 'Ø§Ù„Ø¨Ø±ÙŠØ¯ Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠ',
        'Ø§Ù„Ø¨Ø±ÙŠØ¯Ø§Ù„Ø§Ù„ÙƒØªØ±ÙˆÙ†ÙŠ': 'Ø§Ù„Ø¨Ø±ÙŠØ¯ Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠ',

        'password': 'ÙƒÙ„Ù…Ø© Ø§Ù„Ù…Ø±ÙˆØ±',
        'pass': 'ÙƒÙ„Ù…Ø© Ø§Ù„Ù…Ø±ÙˆØ±',
        'ÙƒÙ„Ù…Ù‡ Ø§Ù„Ù…Ø±ÙˆØ±': 'ÙƒÙ„Ù…Ø© Ø§Ù„Ù…Ø±ÙˆØ±',
        'ÙƒÙ„Ù…Ø©Ø§Ù„Ù…Ø±ÙˆØ±': 'ÙƒÙ„Ù…Ø© Ø§Ù„Ù…Ø±ÙˆØ±',

        'Ø§Ù„Ø­Ø§Ù„Ù‡': 'Ø§Ù„Ø­Ø§Ù„Ø©',
        'status': 'Ø§Ù„Ø­Ø§Ù„Ø©',

        'role': 'Ø§Ù„ØµÙ„Ø§Ø­ÙŠØ©',

        'extra_departments': 'Ø§Ù„Ø£Ù‚Ø³Ø§Ù… Ø§Ù„Ø£Ø®Ø±Ù‰'

    }
    for old, new in rename_map.items():
        if old in df.columns:
            df.rename(columns={old: new}, inplace=True)

    # Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©
    required_cols = ['Ø§Ù„Ø§Ø³Ù…','Ø§Ù„ØµÙ„Ø§Ø­ÙŠØ©','ÙƒÙ„Ù…Ø© Ø§Ù„Ù…Ø±ÙˆØ±','Ø§Ù„Ø¨Ø±ÙŠØ¯ Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠ','Ø§Ù„Ù‚Ø³Ù…','Ø§Ù„Ø­Ø§Ù„Ø©']
    for col in required_cols:
        if col not in df.columns:
            df[col] = ''

    # Ø¥ÙŠØ¬Ø§Ø¯ Ø§Ù„Ù…ÙˆØ¸Ù
    mask = df['Ø§Ù„Ø¨Ø±ÙŠØ¯ Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠ'].astype(str).str.lower().str.strip() == email
    if not mask.any():
        return jsonify({"success": False, "message": "Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯"}), 404

    # Ø­ÙØ¸ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø© Ù‚Ø¨Ù„ Ø§Ù„ØªØ¹Ø¯ÙŠÙ„
    old_email = str(df.loc[mask, 'Ø§Ù„Ø¨Ø±ÙŠØ¯ Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠ'].values[0]).strip().lower()
    old_name  = str(df.loc[mask, 'Ø§Ù„Ø§Ø³Ù…'].values[0]).strip()
    old_dept  = str(df.loc[mask, 'Ø§Ù„Ù‚Ø³Ù…'].values[0]).strip()

    # ØªØ­Ø¯ÙŠØ« Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…ÙˆØ¸Ù
    fields = {
        'name': 'Ø§Ù„Ø§Ø³Ù…',
        'role': 'Ø§Ù„ØµÙ„Ø§Ø­ÙŠØ©',
        'password': 'ÙƒÙ„Ù…Ø© Ø§Ù„Ù…Ø±ÙˆØ±',
        'department': 'Ø§Ù„Ù‚Ø³Ù…',
        'status': 'Ø§Ù„Ø­Ø§Ù„Ø©',
        'extra_departments': 'Ø§Ù„Ø£Ù‚Ø³Ø§Ù… Ø§Ù„Ø£Ø®Ø±Ù‰'
    }

    for key, col in fields.items():
        if key in data and data[key] is not None:
            df.loc[mask, col] = str(data[key]).strip()

    # Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø© Ø¨Ø¹Ø¯ Ø§Ù„ØªØ¹Ø¯ÙŠÙ„
    new_email = str(df.loc[mask, 'Ø§Ù„Ø¨Ø±ÙŠØ¯ Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠ'].values[0]).strip().lower()
    new_name  = str(df.loc[mask, 'Ø§Ù„Ø§Ø³Ù…'].values[0]).strip()
    new_dept  = str(df.loc[mask, 'Ø§Ù„Ù‚Ø³Ù…'].values[0]).strip()

    # Ø­ÙØ¸ Excel
    df.to_excel(DB_PATH, index=False)


    # =============================
    #  ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø·Ù„Ø¨Ø§Øª Ø§Ù„Ù…Ø±ØªØ¨Ø·Ø©
    # =============================
    req_df = load_requests()
    if not req_df.empty:

        # ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø£Ù‚Ø³Ø§Ù… Ø¥Ø°Ø§ ØªØºÙŠÙ‘Ø± Ø§Ù„Ù‚Ø³Ù…
        old_dept_norm = normalize_arabic(old_dept)
        new_dept_norm = normalize_arabic(new_dept)

        if new_dept != old_dept:
            for col in ['Ø§Ù„Ù‚Ø³Ù… Ø§Ù„Ù…Ø±Ø³Ù„', 'Ø§Ù„Ù‚Ø³Ù… Ø§Ù„Ù…Ø³ØªÙ„Ù…']:
                if col in req_df.columns:
                    req_df[col] = req_df[col].apply(
                        lambda x: new_dept if normalize_arabic(str(x)) == old_dept_norm else x
                    )

        # ØªØ­Ø¯ÙŠØ« Ø§Ø³Ù… Ø§Ù„Ù…Ø±Ø³Ù„ Ø¥Ø°Ø§ ØªØºÙŠÙ‘Ø± Ø§Ù„Ø§Ø³Ù…
        if 'Ø§Ø³Ù… Ø§Ù„Ù…Ø±Ø³Ù„' in req_df.columns:
            req_df['Ø§Ø³Ù… Ø§Ù„Ù…Ø±Ø³Ù„'] = req_df['Ø§Ø³Ù… Ø§Ù„Ù…Ø±Ø³Ù„'].apply(
                lambda x: new_name if normalize_arabic(str(x)) == normalize_arabic(old_name) else x
            )

        # ØªØ­Ø¯ÙŠØ« Ø§Ø³Ù… Ø§Ù„Ù…Ø³ØªÙ„Ù… Ø¥Ø°Ø§ ØªØºÙŠÙ‘Ø±
        if 'Ø§Ø³Ù… Ø§Ù„Ù…Ø³ØªÙ„Ù…' in req_df.columns:
            req_df['Ø§Ø³Ù… Ø§Ù„Ù…Ø³ØªÙ„Ù…'] = req_df['Ø§Ø³Ù… Ø§Ù„Ù…Ø³ØªÙ„Ù…'].apply(
                lambda x: new_name if normalize_arabic(str(x)) == normalize_arabic(old_name) else x
            )

        save_requests(req_df)

    # =============================
    #  ØªØ­Ø¯ÙŠØ« Ø¯Ø±Ø¯Ø´Ø§Øª Ø§Ù„Ø·Ù„Ø¨Ø§Øª
    # =============================
    try:
        chats = load_chats()
        if not chats.empty:
            if 'Ø§Ù„Ù…Ø±Ø³Ù„' in chats.columns:
                chats['Ø§Ù„Ù…Ø±Ø³Ù„'] = chats['Ø§Ù„Ù…Ø±Ø³Ù„'].apply(
                    lambda x: new_name if normalize_arabic(str(x)) == normalize_arabic(old_name) else x
                )
            chats.to_excel(CHAT_PATH, index=False)
    except:
        pass

    # =============================
    #  Ù…Ø²Ø§Ù…Ù†Ø© SQLite Ø¨Ø§Ù„ÙƒØ§Ù…Ù„
    # =============================
    try:
        sync_excel_to_sqlite()
    except Exception as e:
        print("SQLite error:", e)

    # =============================
    #  Ù…Ø²Ø§Ù…Ù†Ø© + Ù†Ø³Ø® Ø§Ø­ØªÙŠØ§Ø·ÙŠ
    # =============================
    try:
        full_sync_and_backup()
    except Exception as e:
        print("Backup error:", e)
    # Force logout if updating own account
    try:
        if session.get("user", {}).get("email") == new_email:
            session.clear()
    except:
        pass

    print(f"ğŸ”§ Updated user: {old_email} â†’ {new_email}")

    return jsonify({"success": True})

@app.route('/api/hr/archive_user', methods=['POST'])
def hr_archive_user():
    """Ø£Ø±Ø´ÙØ© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… (ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø­Ø§Ù„Ø© ÙÙ‚Ø· Ø¥Ù† ÙˆØ¬Ø¯Øª)"""
    data = request.get_json() or {}
    email = (data.get('email','') or '').strip().lower()
    if not email:
        return jsonify({"success": False, "message": "Ø§Ù„Ø¨Ø±ÙŠØ¯ Ù…Ø·Ù„ÙˆØ¨"}), 400

    if not os.path.exists(DB_PATH):
        return jsonify({"success": False, "message": "Ù…Ù„Ù Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ† ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯"}), 500

    df = pd.read_excel(DB_PATH)
    sync_excel_to_sqlite()
    df = df.loc[:, ~df.columns.duplicated()]
    # âœ… ØªÙˆØ­ÙŠØ¯ Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© (Ø­ØªÙ‰ Ù„Ùˆ Ø§Ø®ØªÙ„ÙØª Ø§Ù„Ù…Ø³Ø§ÙØ§Øª Ø£Ùˆ Ø§Ù„Ù‡Ù…Ø²Ø§Øª)
    rename_map = {
        'ÙƒÙ„Ù…Ù‡Ø§Ù„Ù…Ø±ÙˆØ±': 'ÙƒÙ„Ù…Ø© Ø§Ù„Ù…Ø±ÙˆØ±',
        'ÙƒÙ„Ù…Ù‡ Ø§Ù„Ù…Ø±ÙˆØ±': 'ÙƒÙ„Ù…Ø© Ø§Ù„Ù…Ø±ÙˆØ±',
        'ÙƒÙ„Ù…Ø©Ø§Ù„Ù…Ø±ÙˆØ±': 'ÙƒÙ„Ù…Ø© Ø§Ù„Ù…Ø±ÙˆØ±',
        'ÙƒÙ„Ù…Ø© Ø§Ù„Ø³Ø±': 'ÙƒÙ„Ù…Ø© Ø§Ù„Ù…Ø±ÙˆØ±',
        'password': 'ÙƒÙ„Ù…Ø© Ø§Ù„Ù…Ø±ÙˆØ±',
        'pass': 'ÙƒÙ„Ù…Ø© Ø§Ù„Ù…Ø±ÙˆØ±',
        'Ø§Ù„Ø§ÙŠÙ…ÙŠÙ„': 'Ø§Ù„Ø¨Ø±ÙŠØ¯ Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠ',
        'email': 'Ø§Ù„Ø¨Ø±ÙŠØ¯ Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠ',
        'Ø§Ù„Ø¨Ø±ÙŠØ¯Ø§Ù„Ø§Ù„ÙƒØªØ±ÙˆÙ†ÙŠ': 'Ø§Ù„Ø¨Ø±ÙŠØ¯ Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠ',
        'Ø§Ù„Ø¨Ø±ÙŠØ¯Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠ': 'Ø§Ù„Ø¨Ø±ÙŠØ¯ Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠ',
        'Ø§Ù„Ø­Ø§Ù„Ù‡': 'Ø§Ù„Ø­Ø§Ù„Ø©',
        'status': 'Ø§Ù„Ø­Ø§Ù„Ø©',
        'role': 'Ø§Ù„ØµÙ„Ø§Ø­ÙŠØ©'
    }
    for old, new in rename_map.items():
        if old in df.columns:
            df.rename(columns={old: new}, inplace=True)

    if 'Ø§Ù„Ø­Ø§Ù„Ø©' not in df.columns:
        return jsonify({"success": False, "message": "Ø¹Ù…ÙˆØ¯ Ø§Ù„Ø­Ø§Ù„Ø© ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯ ÙÙŠ Ø§Ù„Ù…Ù„Ù"}), 500

    mask = df['Ø§Ù„Ø¨Ø±ÙŠØ¯ Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠ'].astype(str).str.lower().str.strip() == email
    if not mask.any():
        return jsonify({"success": False, "message": "Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯"}), 404

    df.loc[mask, 'Ø§Ù„Ø­Ø§Ù„Ø©'] = 'Ù…Ø¤Ø±Ø´Ù'
    df.to_excel(DB_PATH, index=False)
    print(f"ğŸ“¦ ØªÙ…Øª Ø£Ø±Ø´ÙØ© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…: {email}")

    return jsonify({"success": True})

def sync_excel_to_sqlite():
    """ÙŠÙ†Ø³Ø® Ù…Ø­ØªÙˆÙ‰ Excel Ø¥Ù„Ù‰ SQLite Ø¥Ø°Ø§ ØªÙ… Ø§Ù„ØªØ¹Ø¯ÙŠÙ„ Ø¹Ù„Ù‰ Excel"""

    try:
        conn = sqlite3.connect(DB_SQLITE)
        cur = conn.cursor()

        # ğŸ§± Ù…Ø²Ø§Ù…Ù†Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ†
        if os.path.exists(DB_PATH):
            df_users = pd.read_excel(DB_PATH)

            # ğŸ”¹ ØªÙ†Ø¸ÙŠÙ Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ù…Ù† Ø£ÙŠ Ø±Ù…ÙˆØ² ÙˆÙ…Ø³Ø§ÙØ§Øª
            df_users.columns = (
                df_users.columns
                .astype(str)
                .str.replace('\u200f', '', regex=True)
                .str.replace('\u200e', '', regex=True)
                .str.replace(' ', '', regex=True)  # â† ØªØ­Ø°Ù Ø§Ù„Ù…Ø³Ø§ÙØ§Øª Ø¨ÙŠÙ† Ø§Ù„Ø­Ø±ÙˆÙ
                .str.strip()
            )

            # ğŸ§© Ø®Ø±ÙŠØ·Ø© Ø§Ù„ØªØ·Ø¨ÙŠØ¹ Ù„Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…Ø­ØªÙ…Ù„Ø©
            rename_map = {
                'Ø§Ù„Ø§Ø³Ù…': 'Ø§Ù„Ø§Ø³Ù…',
                'Ø§Ù„Ø§ Ø³Ù…': 'Ø§Ù„Ø§Ø³Ù…',
                'Ø§Ù„Ø¥Ø³Ù…': 'Ø§Ù„Ø§Ø³Ù…',
                'Ø§Ù„Ø§Ø³Ù…Ø§Ù„ÙƒØ§Ù…Ù„': 'Ø§Ù„Ø§Ø³Ù…',

                'email': 'Ø§Ù„Ø¨Ø±ÙŠØ¯ Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠ',
                'Ø§Ù„Ø§ÙŠÙ…ÙŠÙ„': 'Ø§Ù„Ø¨Ø±ÙŠØ¯ Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠ',
                'Ø§Ù„Ø¨Ø±ÙŠØ¯Ø§Ù„Ø§Ù„ÙƒØªØ±ÙˆÙ†ÙŠ': 'Ø§Ù„Ø¨Ø±ÙŠØ¯ Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠ',
                'Ø§Ù„Ø¨Ø±ÙŠØ¯Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠ': 'Ø§Ù„Ø¨Ø±ÙŠØ¯ Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠ',

                'Ø§Ù„Ù‚Ø³Ù…': 'Ø§Ù„Ù‚Ø³Ù…',
                'Ø§Ø¯Ø§Ø±Ø©': 'Ø§Ù„Ù‚Ø³Ù…',

                'Ø§Ù„ØµÙ„Ø§Ø­ÙŠÙ‡': 'Ø§Ù„ØµÙ„Ø§Ø­ÙŠØ©',
                'Ø§Ù„ÙˆØ¸ÙŠÙØ©': 'Ø§Ù„ØµÙ„Ø§Ø­ÙŠØ©',
                'role': 'Ø§Ù„ØµÙ„Ø§Ø­ÙŠØ©',

                # ğŸ‘‡ Ø£Ø¶Ù ÙƒÙ„ Ø§Ù„Ø§Ø­ØªÙ…Ø§Ù„Ø§Øª Ø§Ù„Ù…Ù…ÙƒÙ†Ø© Ù„ÙƒÙ„Ù…Ø© Ø§Ù„Ù…Ø±ÙˆØ±
                'ÙƒÙ„Ù…Ù‡Ø§Ù„Ù…Ø±ÙˆØ±': 'ÙƒÙ„Ù…Ø© Ø§Ù„Ù…Ø±ÙˆØ±',
                'ÙƒÙ„Ù…Ù‡ Ø§Ù„Ù…Ø±ÙˆØ±': 'ÙƒÙ„Ù…Ø© Ø§Ù„Ù…Ø±ÙˆØ±',
                'ÙƒÙ„Ù…Ø©Ø§Ù„Ù…Ø±ÙˆØ±': 'ÙƒÙ„Ù…Ø© Ø§Ù„Ù…Ø±ÙˆØ±',
                'ÙƒÙ„Ù…Ø© Ø§Ù„Ù…Ø±ÙˆØ±': 'ÙƒÙ„Ù…Ø© Ø§Ù„Ù…Ø±ÙˆØ±',
                'ÙƒÙ„Ù…Ø©Ø§Ù„Ø³Ø±': 'ÙƒÙ„Ù…Ø© Ø§Ù„Ù…Ø±ÙˆØ±',
                'password': 'ÙƒÙ„Ù…Ø© Ø§Ù„Ù…Ø±ÙˆØ±',
                'pass': 'ÙƒÙ„Ù…Ø© Ø§Ù„Ù…Ø±ÙˆØ±',
            }

            # âœ… Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„ØªØ³Ù…ÙŠØ© Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ ØªØ·Ø§Ø¨Ù‚ Ø¬Ø²Ø¦ÙŠ (Ø­ØªÙ‰ Ù„Ùˆ ÙƒØ§Ù† Ø§Ø®ØªÙ„Ø§Ù Ø¨Ø³ÙŠØ·)
            for col in list(df_users.columns):
                normalized = re.sub(r'[Ø¥Ø£Ø¢Ø§]', 'Ø§', col).replace(' ', '').lower()
                for k, v in rename_map.items():
                    if re.sub(r'[Ø¥Ø£Ø¢Ø§]', 'Ø§', k).replace(' ', '').lower() in normalized:
                        df_users.rename(columns={col: v}, inplace=True)

            # âœ… Ø¶Ù…Ø§Ù† Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© Ù…ÙˆØ¬ÙˆØ¯Ø©
            for col in ['Ø§Ù„Ø§Ø³Ù…', 'Ø§Ù„ØµÙ„Ø§Ø­ÙŠØ©', 'ÙƒÙ„Ù…Ø© Ø§Ù„Ù…Ø±ÙˆØ±', 'Ø§Ù„Ø¨Ø±ÙŠØ¯ Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠ', 'Ø§Ù„Ù‚Ø³Ù…', 'Ø§Ù„Ø­Ø§Ù„Ø©']:
                if col not in df_users.columns:
                    df_users[col] = ''

            # âœ… Ø¥Ø¯Ø®Ø§Ù„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ† Ø¥Ù„Ù‰ SQLite (Ù†Ø³Ø®Ø© Ù…Ø­Ø³Ù‘Ù†Ø© ØªØªÙØ§Ø¯Ù‰ NaN Ø£Ùˆ Ø£Ø¹Ù…Ø¯Ø© ØºÙŠØ± Ù…ÙÙ‡ÙˆÙ…Ø©)
            for _, row in df_users.iterrows():
                try:
                    # ğŸ§© Ø§Ø³ØªØ®Ù„Ø§Øµ Ø¢Ù…Ù† Ù„ÙƒÙ„ Ø­Ù‚Ù„
                    email_val = str(row.get('Ø§Ù„Ø¨Ø±ÙŠØ¯ Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠ', '')).strip().lower()
                    name_val = str(row.get('Ø§Ù„Ø§Ø³Ù…', '')).strip()
                    role_val = str(row.get('Ø§Ù„ØµÙ„Ø§Ø­ÙŠØ©', '')).strip()
                    dept_val = str(row.get('Ø§Ù„Ù‚Ø³Ù…', '')).strip()
                    status_val = str(row.get('Ø§Ù„Ø­Ø§Ù„Ø©', 'Ù†Ø´Ø·')).strip()

                    # ğŸ§© Ù…Ø¹Ø§Ù„Ø¬Ø© ÙƒÙ„Ù…Ø© Ø§Ù„Ù…Ø±ÙˆØ± Ø¨Ø´ÙƒÙ„ Ø®Ø§Øµ (Ù„Ø£Ù†Ù‡Ø§ Ø³Ø¨Ø¨ Ø§Ù„Ø®Ø·Ø£)
                    pwd_val = row.get('ÙƒÙ„Ù…Ø© Ø§Ù„Ù…Ø±ÙˆØ±', '')
                    if isinstance(pwd_val, (pd.Series, pd.DataFrame)):
                        pwd_val = pwd_val.iloc[0] if not pwd_val.empty else ''
                    pwd_val = str(pwd_val).strip()
                    if pwd_val.lower() in ['nan', 'none']:
                        pwd_val = ''

                    cur.execute("""
                        INSERT OR REPLACE INTO users (email, name, role, password, department, status)
                        VALUES (?, ?, ?, ?, ?, ?)
                    """, (email_val, name_val, role_val, pwd_val, dept_val, status_val))
                except Exception as e:
                    print(f"âš ï¸ Error inserting user row: {e}")

        # ğŸ§¾ Ù…Ø²Ø§Ù…Ù†Ø© Ø§Ù„Ø·Ù„Ø¨Ø§Øª
        if os.path.exists(REQUESTS_PATH):
            df_req = pd.read_excel(REQUESTS_PATH)
            df_req.columns = [c.strip() for c in df_req.columns]
            for _, row in df_req.iterrows():
                cur.execute("""
                    INSERT OR REPLACE INTO requests (req_id, date, title, description, sender_dept, receiver_dept, status, assigned_to, updated_by, duration, file_name)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                """, (
                    str(row.get('Ø±Ù‚Ù… Ø§Ù„Ø·Ù„Ø¨', '')).strip(),
                    str(row.get('Ø§Ù„ØªØ§Ø±ÙŠØ®', '')).strip(),
                    str(row.get('Ø§Ù„Ø¹Ù†ÙˆØ§Ù†', '')).strip(),
                    str(row.get('Ø§Ù„ÙˆØµÙ', '')).strip(),
                    str(row.get('Ø§Ù„Ù‚Ø³Ù… Ø§Ù„Ù…Ø±Ø³Ù„', '')).strip(),
                    str(row.get('Ø§Ù„Ù‚Ø³Ù… Ø§Ù„Ù…Ø³ØªÙ„Ù…', '')).strip(),
                    str(row.get('Ø§Ù„Ø­Ø§Ù„Ø©', '')).strip(),
                    str(row.get('Ø§Ù„Ù…ÙˆØ¸Ù Ø§Ù„Ù…Ø¹ÙŠÙ†', '')).strip(),
                    str(row.get('Ø¢Ø®Ø± ØªØ­Ø¯ÙŠØ« Ø¨ÙˆØ§Ø³Ø·Ø©', '')).strip(),
                    str(row.get('Ø§Ù„ÙˆÙ‚Øª', '')).strip(),
                    str(row.get('Ø§Ù„Ù…Ù„Ù', '')).strip(),
                ))

        conn.commit()
        conn.close()
        print("ğŸ” Excel â†’ SQLite sync done successfully âœ…")

    except Exception as e:
        print("âŒ sync_excel_to_sqlite error:", e)

def full_sync_and_backup():
    """Ù…Ø²Ø§Ù…Ù†Ø© Ù…Ù† Excel Ø¥Ù„Ù‰ SQLite ÙÙ‚Ø· + Ø±ÙØ¹ Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠØ©"""
    try:
        # âœ… ÙÙ‚Ø· Excel â†’ SQLite
        sync_excel_to_sqlite()

        # âœ… Ø±ÙØ¹ Ù…Ù„ÙØ§Øª Excel Ø¥Ù„Ù‰ Google Drive (Ø§Ø®ØªÙŠØ§Ø±ÙŠ)
        upload_to_drive(DB_PATH)
        upload_to_drive(REQUESTS_PATH)
        upload_to_drive(CHAT_PATH)

        print("âœ… One-way sync (Excel â†’ SQLite) done successfully.")
    except Exception as e:
        print("âš ï¸ full_sync_and_backup error:", e)

# âœ… Ù…Ø²Ø§Ù…Ù†Ø© Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù‚Ø¨Ù„ Ø§Ù„ØªØ´ØºÙŠÙ„
init_sqlite()
sync_excel_to_sqlite()

import threading
import time

def watch_excel_changes(interval=30):
    """ÙŠØ±Ø§Ù‚Ø¨ Ø£ÙŠ ØªØºÙŠÙŠØ±Ø§Øª ÙÙŠ Ù…Ù„ÙØ§Øª Excel ÙˆÙŠØ¹Ù…Ù„ Ù…Ø²Ø§Ù…Ù†Ø© ØªÙ„Ù‚Ø§Ø¦ÙŠØ©"""
    last_users_time = os.path.getmtime(DB_PATH)
    last_requests_time = os.path.getmtime(REQUESTS_PATH)

    while True:
        time.sleep(interval)
        try:
            # ØªØ­Ù‚Ù‚ Ù…Ù† Ø¢Ø®Ø± ÙˆÙ‚Øª ØªØ¹Ø¯ÙŠÙ„
            new_users_time = os.path.getmtime(DB_PATH)
            new_requests_time = os.path.getmtime(REQUESTS_PATH)

            # Ø¥Ø°Ø§ ØªØºÙŠØ± Ø£ÙŠ Ù…Ù„Ù â†’ Ø£Ø¹Ø¯ Ø§Ù„Ù…Ø²Ø§Ù…Ù†Ø©
            if new_users_time != last_users_time or new_requests_time != last_requests_time:
                print("ğŸ”„ Detected Excel file change, syncing to SQLite...")
                sync_excel_to_sqlite()
                last_users_time = new_users_time
                last_requests_time = new_requests_time

        except Exception as e:
            print("âš ï¸ watch_excel_changes error:", e)

# ğŸ” ØªØ´ØºÙŠÙ„ Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨Ø© ÙÙŠ Ø®ÙŠØ· Ù…Ù†ÙØµÙ„
threading.Thread(target=watch_excel_changes, daemon=True).start()

def auto_backup(interval_hours=24):
    """Ù†Ø³Ø® Ø§Ø­ØªÙŠØ§Ø·ÙŠ ØªÙ„Ù‚Ø§Ø¦ÙŠ Ø¥Ù„Ù‰ Google Drive ÙƒÙ„ ÙØªØ±Ø© Ù…Ø­Ø¯Ø¯Ø©"""
    while True:
        try:
            print("ğŸ• Running scheduled backup...")
            upload_to_drive(DB_PATH)
            upload_to_drive(REQUESTS_PATH)
            # ğŸ“ Ø¥Ø¶Ø§ÙØ© Ù†Ø³Ø®Ø© Ø§Ø­ØªÙŠØ§Ø·ÙŠØ© Ù„Ù…Ù„Ù Ø¯Ø±Ø¯Ø´Ø© Ø§Ù„Ø·Ù„Ø¨Ø§Øª Ø£ÙŠØ¶Ù‹Ø§
            upload_to_drive(CHAT_PATH)
            print("âœ… Backup completed successfully.")
        except Exception as e:
            print("âŒ auto_backup error:", e)
        time.sleep(interval_hours * 3600)


threading.Thread(target=auto_backup, daemon=True).start()



import pandas as pd
from datetime import datetime
import os
import re


# ====== Ø§Ù„Ù…Ø³Ø§Ø±Ø§Øª ======
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
DATA_DIR = os.path.join(BASE_DIR, "data")
os.makedirs(DATA_DIR, exist_ok=True)

CARS_XLSX = os.path.join(DATA_DIR, "cars_data.xlsx")
OIL_XLSX  = os.path.join(DATA_DIR, "oil_history.xlsx")

# Ø£Ø¹Ù…Ø¯Ø© Ù…Ù„Ù Ø§Ù„Ø³ÙŠØ§Ø±Ø§Øª ÙƒÙ…Ø§ Ù‡ÙŠ ÙÙŠ Ø§Ù„Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ù…Ø±ÙÙˆØ¹
AR_COLS = {
    "vin": "Ø±Ù‚Ù… Ø§Ù„Ù‡ÙŠÙƒÙ„",
    "plate": "Ø§Ù„Ù„ÙˆØ­Ø©",
    "brand": "Ø§Ù„Ø´Ø±ÙƒØ©",
    "model": "ÙØ¦Ø© Ø§Ù„Ø³ÙŠØ§Ø±Ø©",
    "color": "Ø§Ù„Ù„ÙˆÙ†",
    "year": "Ø³Ù†Ø© Ø§Ù„ØµÙ†Ø§Ø¹Ø©",
    # Ø£Ø¹Ù…Ø¯Ø© Ø¥Ø¶Ø§ÙÙŠØ© Ø§Ø®ØªÙŠØ§Ø±ÙŠØ© Ù†Ø­Ø¯Ù‘ÙØ«Ù‡Ø§ Ù…Ù† Ø¢Ø®Ø± ØªØºÙŠÙŠØ± Ø²ÙŠØª
    "last_oil_date": "ØªØ§Ø±ÙŠØ® ØªØºÙŠÙŠØ± Ø§Ù„Ø²ÙŠØª",
    "last_odometer": "Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø³ÙŠØ§Ø±Ø©",
    "last_oil_run": "Ù…Ù…Ø´Ù‰ Ø§Ù„Ø²ÙŠØª",
    "updated_at": "Ø¢Ø®Ø± ØªØ­Ø¯ÙŠØ«"
}

# Ø¬Ø¯ÙˆÙ„ Ø³Ø¬Ù„ Ø§Ù„Ø²ÙŠØª
H_COLS = {
    "plate": "Ø§Ù„Ù„ÙˆØ­Ø©",
    "vin": "Ø±Ù‚Ù… Ø§Ù„Ù‡ÙŠÙƒÙ„",
    "date": "ØªØ§Ø±ÙŠØ® Ø§Ù„ØªØºÙŠÙŠØ±",
    "odometer": "Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø³ÙŠØ§Ø±Ø©",
    "oil_run": "Ù…Ù…Ø´Ù‰ Ø§Ù„Ø²ÙŠØª",
    "notes": "Ù…Ù„Ø§Ø­Ø¸Ø§Øª",
    "created_at": "ØªØ§Ø±ÙŠØ® Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„"
}

def _now():
    return datetime.now().strftime("%Y-%m-%d %H:%M:%S")

def ensure_files():
    # Ù…Ù„Ù Ø§Ù„Ø³ÙŠØ§Ø±Ø§Øª ÙŠØ¬Ø¨ Ø£Ù† ÙŠÙƒÙˆÙ† Ù…ÙˆØ¬ÙˆØ¯Ø§Ù‹ (Ù…Ù†Ùƒ)
    if not os.path.exists(CARS_XLSX):
        # Ù†Ù†Ø´Ø¦ Ù…Ù„ÙØ§Ù‹ ÙØ§Ø±ØºØ§Ù‹ Ø¨Ù†ÙØ³ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© Ù„ÙƒÙŠ Ù„Ø§ ÙŠØªØ¹Ø·Ù„ Ø§Ù„ØªØ´ØºÙŠÙ„
        df = pd.DataFrame(columns=[AR_COLS[c] for c in ["vin","plate","brand","model","color","year"]])
        df.to_excel(CARS_XLSX, index=False)
    # Ù…Ù„Ù Ø³Ø¬Ù„ Ø§Ù„Ø²ÙŠØª Ù†Ù†Ø´Ø¦Ù‡ Ø¥Ù† Ù„Ù… ÙŠÙˆØ¬Ø¯
    if not os.path.exists(OIL_XLSX):
        hdf = pd.DataFrame(columns=[H_COLS[k] for k in ["plate","vin","date","odometer","oil_run","notes","created_at"]])
        hdf.to_excel(OIL_XLSX, index=False)

def read_cars():
    ensure_files()
    df = pd.read_excel(CARS_XLSX, dtype=str).fillna("")

    # âœ… ØªÙˆØ­ÙŠØ¯ Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©
    rename_map = {}
    for c in df.columns:
        clean = c.strip().replace(" ", "")
        if clean in ["ÙØ¦Ù‰Ø©Ø§Ù„Ø³ÙŠØ§Ø±Ø©", "ÙØ¦Ø©Ø§Ù„Ø³ÙŠØ§Ø±Ù‡", "ÙØ¦Ø©Ø§Ù„Ø³ÙŠØ§Ø±Ø©"]:
            rename_map[c] = "ÙØ¦Ø© Ø§Ù„Ø³ÙŠØ§Ø±Ø©"
        elif clean in ["Ø§Ù„Ù„ÙˆØ­Ù‡", "Ø§Ù„ÙˆØ­Ù‡", "Ø§Ù„Ù„ÙˆØ­Ø©"]:
            rename_map[c] = "Ø§Ù„Ù„ÙˆØ­Ø©"
        elif clean in ["Ø±Ù‚Ù…Ø§Ù„Ù‡ÙŠÙƒÙ„", "Ø±Ù‚Ù…Ù‡ÙŠÙƒÙ„"]:
            rename_map[c] = "Ø±Ù‚Ù… Ø§Ù„Ù‡ÙŠÙƒÙ„"
        elif clean in ["Ø§Ù„Ù„ÙˆÙ†"]:
            rename_map[c] = "Ø§Ù„Ù„ÙˆÙ†"
        elif clean in ["Ø§Ù„Ø´Ø±ÙƒÙ‡"]:
            rename_map[c] = "Ø§Ù„Ø´Ø±ÙƒØ©"
        elif clean in ["Ø³Ù†Ù‡Ø§Ø§Ù„ØµÙ†Ø§Ø¹Ù‡", "Ø³Ù†Ø©Ø§Ù„ØµÙ†Ø§Ø¹Ù‡"]:
            rename_map[c] = "Ø³Ù†Ø© Ø§Ù„ØµÙ†Ø§Ø¹Ø©"
    if rename_map:
        df = df.rename(columns=rename_map)

    # âœ… ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù†ØµÙˆØµ Ù…Ù† Ø§Ù„Ø±Ù…ÙˆØ² Ø§Ù„Ø®ÙÙŠØ© ÙˆØ§Ù„ÙØ±Ø§ØºØ§Øª Ø§Ù„ØºØ±ÙŠØ¨Ø©
    def clean_text(x):
        if not isinstance(x, str):
            return str(x)
        x = x.strip()
        x = x.replace("\u200f", "").replace("\u200e", "")  # Ø±Ù…ÙˆØ² Ø§Ù„Ø§ØªØ¬Ø§Ù‡
        x = x.replace("Ù€", "")  # Ø´Ø±Ø·Ø© Ø§Ù„ØªÙ…Ø¯ÙŠØ¯
        x = re.sub(r"\s+", " ", x)  # ØªÙ‚Ù„ÙŠÙ„ Ø§Ù„Ù…Ø³Ø§ÙØ§Øª
        return x

    for col in df.columns:
        df[col] = df[col].apply(clean_text)

    # âœ… ØªØ£ÙƒØ¯ Ù…Ù† Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ø¥Ø¶Ø§ÙÙŠØ© Ø§Ù„Ø®Ø§ØµØ© Ø¨ØªÙˆØ§Ø±ÙŠØ® Ø§Ù„Ø²ÙŠØª
    for c in ["last_oil_date", "last_odometer", "last_oil_run", "updated_at"]:
        col = AR_COLS[c]
        if col not in df.columns:
            df[col] = ""

    return df

def write_cars(df):
    df.to_excel(CARS_XLSX, index=False)

def read_oil():
    ensure_files()
    return pd.read_excel(OIL_XLSX, dtype=str).fillna("")

def write_oil(df):
    df.to_excel(OIL_XLSX, index=False)

def delete_history_by_plate_or_vin(old_plate: str, vin: str):
    """ÙŠØ­Ø°Ù ÙƒÙ„ Ø³Ø¬Ù„Ø§Øª Ø§Ù„Ø²ÙŠØª Ø§Ù„Ù…Ø±ØªØ¨Ø·Ø© Ø¨Ø§Ù„Ù„ÙˆØ­Ø© Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø© Ø£Ùˆ Ø±Ù‚Ù… Ø§Ù„Ù‡ÙŠÙƒÙ„"""
    h = read_oil()
    opn = normalize_plate(old_plate or "")
    if h.empty:
        return
    m = pd.Series([False]*len(h))
    if old_plate:
        m = m | (h[H_COLS["plate"]].astype(str).apply(normalize_plate) == opn)
    if vin:
        m = m | (h[H_COLS["vin"]].astype(str) == str(vin))
    if m.any():
        h = h[~m].copy()
        write_oil(h)

def normalize_plate(s: str) -> str:
    s = (s or "").strip()
    # Ø¥Ø²Ø§Ù„Ø© Ù…Ø³Ø§ÙØ§Øª ÙˆØªØ·Ø¨ÙŠØ¹ Ø¨Ø³ÙŠØ· Ù„Ù„Ø­Ø±ÙˆÙ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„Ù…ØªÙØ±Ù‚Ø©
    s = s.replace(" ", "").replace("Ù€", "")
    s = s.replace("\u200f","").replace("\u200e","")
    return s

@app.route("/maintenance.html")
def maintenance_page():
    return render_template("maintenance.html")

@app.route("/rental.html")
def rental_page():
    return render_template("rental.html")

# ---------- API: Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ø³ÙŠØ§Ø±Ø§Øª Ù…Ø¹ Ø¨Ø­Ø« + ÙÙ„ØªØ± ----------
@app.route("/api/cars", methods=["GET"])
def api_cars():
    q = (request.args.get("q") or "").strip()
    limit = (request.args.get("limit") or "all").lower()
    df = read_cars()

    if q:
        qn = normalize_plate(q)
        # Ù†Ø¨Ø­Ø« ÙÙŠ Ø§Ù„Ù„ÙˆØ­Ø© ÙˆØ§Ù„Ù‡ÙŠÙƒÙ„ ÙˆØ¨Ù‚ÙŠØ© Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©
        mask = (
            df[AR_COLS["plate"]].astype(str).apply(normalize_plate).str.contains(qn, na=False) |
            df[AR_COLS["vin"]].astype(str).str.contains(q, na=False) |
            df[AR_COLS["brand"]].astype(str).str.contains(q, case=False, na=False) |
            df[AR_COLS["model"]].astype(str).str.contains(q, case=False, na=False) |
            df[AR_COLS["color"]].astype(str).str.contains(q, case=False, na=False) |
            df[AR_COLS["year"]].astype(str).str.contains(q, na=False)
        )
        df = df[mask]

    # Ø§Ù„ØªØ±ØªÙŠØ¨ Ù…Ù† Ø§Ù„Ø£Ø­Ø¯Ø« ØªØ­Ø¯ÙŠØ«Ø§Ù‹ Ù„Ù„Ø£Ù‚Ø¯Ù…
    if AR_COLS["updated_at"] in df.columns:
        df = df.copy()
        # Ø­Ø§ÙˆÙ„ ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØªØ§Ø±ÙŠØ® Ù„Ù„ØªØ±ØªÙŠØ¨
        try:
            df["_u"] = pd.to_datetime(df[AR_COLS["updated_at"]], errors="coerce")
            df = df.sort_values(by="_u", ascending=False)
            df = df.drop(columns=["_u"])
        except Exception:
            pass

    if limit.isdigit():
        df = df.head(int(limit))

    # Ù†Ø¹ÙŠØ¯ ØµÙÙˆÙ ÙƒÙ€ JSON
    records = df.to_dict(orient="records")
    return jsonify(records)

# ---------- API: ØªÙØ§ØµÙŠÙ„ Ø³ÙŠØ§Ø±Ø© ÙˆØ§Ø­Ø¯Ø© ----------
@app.route("/api/car/<plate>", methods=["GET"])
def api_car_detail(plate):
    df = read_cars()
    pn = normalize_plate(plate)
    plate = requests.utils.unquote(plate)

    # Ù†Ø¨Ø­Ø« Ø¨Ø§Ù„Ù„ÙˆØ­Ø© Ø£Ùˆ Ø±Ù‚Ù… Ø§Ù„Ù‡ÙŠÙƒÙ„
    row = df[
        (df[AR_COLS["plate"]].astype(str).apply(normalize_plate) == pn)
        | (df[AR_COLS["vin"]].astype(str) == plate)
    ]

    if row.empty:
        return jsonify({"ok": False, "msg": "Ø§Ù„Ø³ÙŠØ§Ø±Ø© ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯Ø©"}), 404
    return jsonify({"ok": True, "data": row.iloc[0].to_dict()})

# ---------- API: Ø¥Ø¶Ø§ÙØ©/ØªØ­Ø¯ÙŠØ« Ø³ÙŠØ§Ø±Ø© (ÙˆØ±Ø´Ø© ÙÙ‚Ø·) ----------
@app.route("/api/car/save", methods=["POST"])
def api_car_save():
    data = request.json or {}
    vin   = (data.get("vin") or "").strip()
    plate = (data.get("plate") or "").strip()
    brand = (data.get("brand") or "").strip()
    model = (data.get("model") or "").strip()
    color = (data.get("color") or "").strip()
    year  = (data.get("year") or "").strip()

    if not vin:
        return jsonify({"ok": False, "msg": "Ø±Ù‚Ù… Ø§Ù„Ù‡ÙŠÙƒÙ„ Ù…Ø·Ù„ÙˆØ¨"}), 400

    df = read_cars()

    # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ø³ÙŠØ§Ø±Ø© Ø­Ø³Ø¨ VIN (VIN Ù„Ø§ ÙŠØªØºÙŠØ±)
    exist_idx = df.index[df[AR_COLS["vin"]].astype(str) == vin].tolist()
    if exist_idx:
        i = exist_idx[0]

        # ÙØ­Øµ ØªØºÙŠÙŠØ± Ø§Ù„Ù„ÙˆØ­Ø©
        old_plate = str(df.at[i, AR_COLS["plate"]] or "").strip()
        new_plate = plate.strip() if plate else old_plate
        old_norm = normalize_plate(old_plate)
        new_norm = normalize_plate(new_plate)

        # ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø­Ù‚ÙˆÙ„ Ø§Ù„Ù…Ø³Ù…ÙˆØ­Ø© ÙÙ‚Ø· (VIN Ø«Ø§Ø¨Øª)
        if plate:
            df.at[i, AR_COLS["plate"]] = new_plate
        if brand: df.at[i, AR_COLS["brand"]] = brand
        if model: df.at[i, AR_COLS["model"]] = model
        if color: df.at[i, AR_COLS["color"]] = color
        if year:  df.at[i, AR_COLS["year"]]  = year

        # âœ… Ø¥Ø°Ø§ ØªØºÙŠÙ‘Ø±Øª Ø§Ù„Ù„ÙˆØ­Ø© â†’ Ø§Ø­Ø°Ù ÙƒÙ„ Ø³Ø¬Ù„ Ø§Ù„Ø²ÙŠØª Ø§Ù„Ù…Ø±ØªØ¨Ø·
        if old_plate and (new_norm != old_norm):
            delete_history_by_plate_or_vin(old_plate=old_plate, vin=vin)
            for c in ["last_oil_date", "last_odometer", "last_oil_run"]:
                df.at[i, AR_COLS[c]] = ""

        df.at[i, AR_COLS["updated_at"]] = _now()

    else:
        # Ø¥Ù†Ø´Ø§Ø¡ Ø³Ø¬Ù„ Ø¬Ø¯ÙŠØ¯ (ÙŠÙØ³Ù…Ø­ Ø¨Ø¥Ø¯Ø®Ø§Ù„ VIN Ø¬Ø¯ÙŠØ¯ Ù„Ø£Ù† Ù‡Ø°Ø§ ØªØ³Ø¬ÙŠÙ„ Ø¬Ø¯ÙŠØ¯)
        new_row = {
            AR_COLS["vin"]: vin,
            AR_COLS["plate"]: plate,
            AR_COLS["brand"]: brand,
            AR_COLS["model"]: model,
            AR_COLS["color"]: color,
            AR_COLS["year"]: year,
            AR_COLS["last_oil_date"]: "",
            AR_COLS["last_odometer"]: "",
            AR_COLS["last_oil_run"]: "",
            AR_COLS["updated_at"]: _now(),
        }
        df = pd.concat([pd.DataFrame([new_row]), df], ignore_index=True)

    write_cars(df)
    return jsonify({"ok": True, "msg": "ØªÙ… Ø§Ù„Ø­ÙØ¸ Ø¨Ù†Ø¬Ø§Ø­"})

# ---------- API: Ø³Ø¬Ù„ Ø§Ù„Ø²ÙŠØª Ù„Ø³ÙŠØ§Ø±Ø© ----------
@app.route("/api/oil_history/<plate>", methods=["GET"])
def api_oil_history(plate):
    h = read_oil()
    pn = normalize_plate(plate)
    mask = h[H_COLS["plate"]].astype(str).apply(normalize_plate) == pn
    sub = h[mask].copy()
    # Ø£Ø­Ø¯Ø« Ø³Ø¬Ù„ Ø£ÙˆÙ„Ø§Ù‹
    try:
        sub["_c"] = pd.to_datetime(sub[H_COLS["created_at"]], errors="coerce")
        sub = sub.sort_values(by="_c", ascending=False).drop(columns=["_c"])
    except Exception:
        pass
    return jsonify(sub.to_dict(orient="records"))

# ---------- API: Ø¥Ø¶Ø§ÙØ© Ø³Ø¬Ù„ ØªØºÙŠÙŠØ± Ø²ÙŠØª (ÙˆØ±Ø´Ø© ÙÙ‚Ø·) ----------
@app.route("/api/oil_history/add", methods=["POST"])
def api_oil_add():
    data = request.json or {}
    plate    = (data.get("plate") or "").strip()
    vin      = (data.get("vin") or "").strip()
    date     = (data.get("date") or "").strip()
    odometer = (data.get("odometer") or "").strip()
    oil_run  = (data.get("oil_run") or "").strip()
    notes    = (data.get("notes") or "").strip()

    if not plate and not vin:
        return jsonify({"ok": False, "msg": "Ø§Ù„Ù„ÙˆØ­Ø© Ø£Ùˆ Ø±Ù‚Ù… Ø§Ù„Ù‡ÙŠÙƒÙ„ Ù…Ø·Ù„ÙˆØ¨"}), 400

    # âœ… Ø¥Ù„Ø²Ø§Ù…ÙŠØ© Ø§Ù„ØªØ§Ø±ÙŠØ® ÙˆØ§Ù„Ù…Ù…Ø´Ù‰
    if not date or not odometer:
        return jsonify({"ok": False, "msg": "ÙŠØ¬Ø¨ Ø¥Ø¯Ø®Ø§Ù„ Ø§Ù„ØªØ§Ø±ÙŠØ® ÙˆØ¹Ø¯Ø§Ø¯ Ø§Ù„Ø³ÙŠØ§Ø±Ø©"}), 400

    h = read_oil()
    newh = {
        H_COLS["plate"]: plate,
        H_COLS["vin"]: vin,
        H_COLS["date"]: date,
        H_COLS["odometer"]: odometer,
        H_COLS["oil_run"]: oil_run,
        H_COLS["notes"]: notes,
        H_COLS["created_at"]: _now()
    }
    h = pd.concat([pd.DataFrame([newh]), h], ignore_index=True)
    write_oil(h)

    # ØªØ­Ø¯ÙŠØ« Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø³ÙŠØ§Ø±Ø©
    if vin or plate:
        df = read_cars()
        if vin:
            idx = df.index[df[AR_COLS["vin"]].astype(str) == vin].tolist()
        else:
            pn = normalize_plate(plate)
            idx = df.index[df[AR_COLS["plate"]].astype(str).apply(normalize_plate) == pn].tolist()
        if idx:
            i = idx[0]
            df.at[i, AR_COLS["last_oil_date"]] = date
            df.at[i, AR_COLS["last_odometer"]] = odometer
            if oil_run:
                df.at[i, AR_COLS["last_oil_run"]] = oil_run
            df.at[i, AR_COLS["updated_at"]] = _now()
            write_cars(df)

    return jsonify({"ok": True, "msg": "ØªÙ… Ø¥Ø¶Ø§ÙØ© Ø³Ø¬Ù„ ØªØºÙŠÙŠØ± Ø§Ù„Ø²ÙŠØª Ø¨Ù†Ø¬Ø§Ø­"})



@app.route('/api/admin/requests/list', methods=['POST'])
def admin_list_requests():
    try:
        df = load_requests()
        if df.empty:
            return jsonify([])

        # ğŸ”¥ Ù„Ø§ ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ Boolean!
        # ÙÙ‚Ø· ØªØ£ÙƒØ¯ Ø£Ù† Ø§Ù„Ù‚ÙŠÙ…Ø© "1" Ø£Ùˆ "0"
        df["Ù…Ø¤Ø±Ø´Ù"] = df["Ù…Ø¤Ø±Ø´Ù"].astype(str).str.strip()
        df["Ù…Ø¤Ø±Ø´Ù"] = df["Ù…Ø¤Ø±Ø´Ù"].apply(lambda x: "1" if x in ["1","Ù†Ø¹Ù…","true","True","yes","y"] else "0")

        return jsonify(df.fillna('').to_dict(orient='records'))

    except Exception as e:
        print("âŒ admin_list_requests error:", e)
        return jsonify([]), 500

@app.route("/api/admin/requests/archive", methods=["POST"])
def archive_request():
    data = request.get_json()
    req_id = str(data.get("request_id")).strip()
    archive = data.get("archive", False)
    updated_by = data.get("updated_by", "admin")

    # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ù„Ù Ø¨Ø¯ÙˆÙ† Ø£ÙŠ ØªØ·Ø¨ÙŠØ¹
    df = pd.read_excel(REQUESTS_XLSX, dtype=str)

    # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù‚ÙŠÙ…
    df.columns = df.columns.str.strip()
    df = df.applymap(lambda x: x.strip() if isinstance(x,str) else x)

    # Ø§Ù„Ø¨Ø­Ø« Ø§Ù„ØµØ­ÙŠØ­ Ø¹Ù† Ø±Ù‚Ù… Ø§Ù„Ø·Ù„Ø¨
    idx = df.index[df["Ø±Ù‚Ù… Ø§Ù„Ø·Ù„Ø¨"].astype(str).str.strip() == req_id]

    if len(idx) == 0:
        print("âŒ Ø±Ù‚Ù… Ø§Ù„Ø·Ù„Ø¨ Ù„Ù… ÙŠÙØ¹Ø«Ø± Ø¹Ù„ÙŠÙ‡ Ø¯Ø§Ø®Ù„ Excel:", req_id)
        return jsonify({"success": False, "msg": "Request not found"})

    row = idx[0]

    # ØªØ¹Ø¯ÙŠÙ„ Ù‚ÙŠÙ…Ø© Ø§Ù„Ù…Ø¤Ø±Ø´Ù
    df.loc[row, "Ù…Ø¤Ø±Ø´Ù"] = "1" if archive else "0"
    df.loc[row, "Ø¢Ø®Ø± ØªØ­Ø¯ÙŠØ« Ø¨ÙˆØ§Ø³Ø·Ø©"] = updated_by

    # Ø­ÙØ¸ Ø§Ù„ØªØ¹Ø¯ÙŠÙ„
    df.to_excel(REQUESTS_XLSX, index=False)

    print("âœ… ØªÙ… ØªØ­Ø¯ÙŠØ« Ø£Ø±Ø´ÙØ© Ø§Ù„Ø·Ù„Ø¨:", req_id)
    return jsonify({"success": True})



@app.route('/api/get_departments')
def get_departments():
    import pandas as pd
    try:
        df = pd.read_excel(USERS_XLSX)

        # Ø§Ù„Ø£Ù‚Ø³Ø§Ù… Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©
        main_depts = set()

        if "Ø§Ù„Ù‚Ø³Ù…" in df.columns:
            for d in df["Ø§Ù„Ù‚Ø³Ù…"].dropna().tolist():
                d = str(d).strip()
                if d:
                    main_depts.add(d)

        # Ø§Ù„Ø£Ù‚Ø³Ø§Ù… Ø§Ù„Ø¥Ø¶Ø§ÙÙŠØ© (Ø§Ù„Ø£Ù‚Ø³Ø§Ù… Ø§Ù„Ø£Ø®Ø±Ù‰)
        extra_depts = set()

        if "Ø§Ù„Ø£Ù‚Ø³Ø§Ù… Ø§Ù„Ø£Ø®Ø±Ù‰" in df.columns:
            for row in df["Ø§Ù„Ø£Ù‚Ø³Ø§Ù… Ø§Ù„Ø£Ø®Ø±Ù‰"].dropna().tolist():
                row = str(row).strip()
                if row:
                    # ØªÙ‚Ø³ÙŠÙ… Ø¨Ø§Ù„Ù‚ÙŠÙ…: "ØŒ" Ø£Ùˆ ","
                    parts = re.split(r"[ØŒ,]", row)
                    for p in parts:
                        p = p.strip()
                        if p:
                            extra_depts.add(p)

        # Ø¯Ù…Ø¬ Ø§Ù„Ø£Ù‚Ø³Ø§Ù…
        all_depts = main_depts.union(extra_depts)

        # Ø§Ø³ØªØ«Ù†Ø§Ø¡ Ø§Ù„Ø£Ù‚Ø³Ø§Ù… Ø§Ù„Ø®Ø§ØµØ© Ø¨Ø§Ù„Ø£Ø¯Ù…Ù†
        blacklist = ["admin", "Ø§Ø¯Ù…Ù†", "Ù…Ø´Ø±Ù", "Ù…Ø¯ÙŠØ± Ù†Ø¸Ø§Ù…", "Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ù†Ø¸Ø§Ù…"]

        clean = []
        for d in all_depts:
            dn = str(d).strip()
            dn_norm = dn.replace("Ø¥", "Ø§").replace("Ø£", "Ø§").replace("Ø¢", "Ø§").lower()
            if any(b in dn_norm for b in blacklist):
                continue
            clean.append(dn)

        # ØªØ±ØªÙŠØ¨ Ø£Ø¨Ø¬Ø¯ÙŠ
        clean = sorted(clean)

        return jsonify({"departments": clean})

    except Exception as e:
        return jsonify({"departments": [], "error": str(e)})

# ============================================================
# ğŸ”Œ CORE SYSTEM (stor7s-backend) INJECTION
# ============================================================

def require_core_access():
    user = session.get("user")
    if not user:
        return False

    apps = user.get("apps", [])
    if not isinstance(apps, list):
        return False

    # Ø§Ù„Ø³Ù…Ø§Ø­ Ø¨Ø§Ù„Ø¯Ø®ÙˆÙ„ Ø¥Ø°Ø§ Ù„Ø¯ÙŠÙ‡ Ù†Ø¸Ø§Ù… Ø§Ù„Ù…Ø³ØªÙˆØ¯Ø¹
    return ("warehouse" in apps) or ("core" in apps) or ("all" in apps)

@app.route("/core")
def core_entry():
    if not session.get("user"):
        return redirect("/Login.html")

    user = session["user"]

    apps = user.get("apps", [])
    if isinstance(apps, str):
        apps = [a.strip().lower() for a in apps.split(",")]

    role_norm = normalize_role(user.get("role", ""))

    allowed_by_apps = any(a in apps for a in ["warehouse", "core", "all"])
    allowed_by_role = role_norm in ["manager", "general_manager", "admin"]

    if not (allowed_by_apps or allowed_by_role):
        return "ğŸš« ØºÙŠØ± Ù…ØµØ±Ø­ Ù„Ùƒ Ø¨Ø§Ù„Ø¯Ø®ÙˆÙ„ Ø¥Ù„Ù‰ Ù†Ø¸Ø§Ù… Ø§Ù„Ù…Ø³ØªÙˆØ¯Ø¹ ÙˆØ§Ù„Ø¹Ù‡Ø¯", 403

    role = normalize_arabic(user.get("role", ""))
    dept = normalize_arabic(user.get("department", ""))

    page = None  # â­ ØªØ¹Ø±ÙŠÙ ØµØ±ÙŠØ­

    # ===============================
    # 1ï¸âƒ£ Ø£ÙˆÙ„ÙˆÙŠØ© Ù…Ø¯ÙŠØ± Ø§Ù„Ù‚Ø³Ù…
    # ===============================
    if role_norm == "manager":
        page = "manager1.html"

    # ===============================
    # 2ï¸âƒ£ Ø§Ù„ØªÙˆØ¬ÙŠÙ‡ Ø­Ø³Ø¨ Ø§Ù„Ù‚Ø³Ù…
    # ===============================
    elif "ØªÙ‚Ù†ÙŠØ©" in dept or "it" in dept:
        page = "it1.html"

    elif "Ù…Ø§Ù„ÙŠ" in dept:
        page = "finance1.html"

    elif "Ù…Ø´ØªØ±ÙŠØ§Øª" in dept:
        page = "purchasing1.html"

    elif "Ù…ÙˆØ§Ø±Ø¯" in dept:
        page = "hr1.html"

    elif "Ø§Ø¯Ø§Ø±Ø©" in dept and "Ø§Ù„Ø¹Ø§Ù…Ø©" in dept:
        page = "admin1.html"

    # ===============================
    # 2ï¸âƒ£ fallback Ø­Ø³Ø¨ Ø§Ù„ØµÙ„Ø§Ø­ÙŠØ© ÙÙ‚Ø·
    # ===============================
    if not page:
        if role == "manager":
            page = "manager1.html"

        elif role in ["general_manager", "admin"]:
            page = "admin1.html"

        elif role == "employee":
            page = "employee1.html"

    # ===============================
    # 3ï¸âƒ£ Ø­Ù…Ø§ÙŠØ© Ù†Ù‡Ø§Ø¦ÙŠØ©
    # ===============================
    if not page:
        return "âŒ Ù„Ø§ ØªÙˆØ¬Ø¯ ØµÙØ­Ø© Ù…Ù†Ø§Ø³Ø¨Ø© Ù„Ù‡Ø°Ø§ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…", 403

    return render_template(f"templates1/{page}")

# ğŸ“¡ Core APIs (Blueprints)
from modules.employee import api as core_employee_api
from modules.manager import api as core_manager_api
from modules.purchasing import api as core_purchasing_api
from modules.it import api as core_it_api
from modules.hr import api as core_hr_api
from modules.finance import api as core_finance_api
from modules.admin import api as core_admin_api

app.register_blueprint(core_employee_api, url_prefix="/api/core/employee")
app.register_blueprint(core_manager_api, url_prefix="/api/core/manager")
app.register_blueprint(core_purchasing_api, url_prefix="/api/core/purchasing")
app.register_blueprint(core_it_api, url_prefix="/api/core/it")
app.register_blueprint(core_hr_api, url_prefix="/api/core/hr")
app.register_blueprint(core_finance_api, url_prefix="/api/core/finance")
app.register_blueprint(core_admin_api, url_prefix="/api/core/admin")

# ============== Ø§Ù„ØªØ´ØºÙŠÙ„ ==============
if __name__ == "__main__":
    import os
    port = int(os.environ.get("PORT", 5000))
    app.run(host="0.0.0.0", port=port)
